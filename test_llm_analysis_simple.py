#!/usr/bin/env python3
"""
LLMåˆ†æä¸æ¨ç†å¼•æ“ç®€åŒ–æµ‹è¯•
"""

import asyncio
import sys
import os
from datetime import datetime, timedelta
from typing import List, Dict, Any

# æ·»åŠ è·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

# æ¨¡æ‹Ÿå¿…è¦çš„ç±»
class MockFusionSignal:
    def __init__(self, signal_type, signal_strength, overall_confidence, risk_score):
        self.signal_type = signal_type
        self.signal_strength = signal_strength
        self.overall_confidence = overall_confidence
        self.risk_score = risk_score
        self.components = []

class MockSignalComponent:
    def __init__(self, indicator_name, confidence):
        self.indicator_name = indicator_name
        self.confidence = confidence

class MockShortSignalType:
    TREND_REVERSAL = "trend_reversal"
    RSI_OVERBOUGHT = "rsi_overbought"

class MockShortSignalStrength:
    MODERATE = "moderate"
    STRONG = "strong"

from short_analyst.llm_analysis.llm_engine import LLMAnalysisEngine
from short_analyst.llm_analysis.llm_models import (
    LLMAnalysisInput,
    AnalysisType,
    RiskTolerance,
    TimeHorizon,
    SentimentPolarity
)

async def test_basic_llm_analysis():
    """æµ‹è¯•åŸºæœ¬LLMåˆ†æåŠŸèƒ½"""
    print("=== æµ‹è¯•åŸºæœ¬LLMåˆ†æåŠŸèƒ½ ===")

    # åˆ›å»ºLLMåˆ†æå¼•æ“
    llm_config = {
        'provider': 'mock',
        'model': 'gpt-4',
        'max_tokens': 1000,
        'temperature': 0.3,
        'enable_cache': True,
        'enable_context': True
    }

    llm_engine = LLMAnalysisEngine(llm_config)

    try:
        # åˆ›å»ºæµ‹è¯•è¾“å…¥æ•°æ®
        mock_signals = [
            MockFusionSignal(
                signal_type=MockShortSignalType.TREND_REVERSAL,
                signal_strength=MockShortSignalStrength.MODERATE,
                overall_confidence=0.75,
                risk_score=0.4
            ),
            MockFusionSignal(
                signal_type=MockShortSignalType.RSI_OVERBOUGHT,
                signal_strength=MockShortSignalStrength.STRONG,
                overall_confidence=0.85,
                risk_score=0.3
            )
        ]

        analysis_input = LLMAnalysisInput(
            symbol="BTC/USDT",
            current_price=45000.0,
            price_change_24h=-2.5,
            volume_24h=2500000000,
            market_cap=850000000000,
            fusion_signals=mock_signals,
            news_headlines=[
                "Bitcoiné¢ä¸´ç›‘ç®¡å‹åŠ›",
                "æŠ€æœ¯æŒ‡æ ‡æ˜¾ç¤ºè¶…ä¹°ä¿¡å·"
            ],
            social_media_sentiment=SentimentPolarity.BEARISH,
            fear_greed_index=72,
            market_conditions="é«˜æ³¢åŠ¨ç‡",
            trend_context="çŸ­æœŸä¸‹è·Œè¶‹åŠ¿",
            analysis_types=[
                AnalysisType.MARKET_SENTIMENT,
                AnalysisType.TECHNICAL_EXPLANATION,
                AnalysisType.RISK_ASSESSMENT,
                AnalysisType.TRADING_DECISION
            ],
            risk_tolerance=RiskTolerance.MODERATE,
            time_horizon=TimeHorizon.SHORT_TERM
        )

        # æ‰§è¡Œåˆ†æ
        print("æ‰§è¡ŒLLMåˆ†æ...")
        result = await llm_engine.analyze(analysis_input)

        print(f"âœ… åˆ†æå®Œæˆ")
        print(f"äº¤æ˜“å¯¹: {result.symbol}")
        print(f"æ•´ä½“è¯„åˆ†: {result.overall_score:.2f}")
        print(f"ç½®ä¿¡åº¦: {result.confidence.name}")

        # æ£€æŸ¥åˆ†æç»“æœ
        if result.market_sentiment:
            print(f"å¸‚åœºæƒ…ç»ª: {result.market_sentiment.overall_sentiment.name}")
            print(f"æƒ…ç»ªåˆ†æ•°: {result.market_sentiment.sentiment_score:.2f}")

        if result.technical_explanations:
            print(f"æŠ€æœ¯è§£é‡Šæ•°é‡: {len(result.technical_explanations)}")

        if result.risk_assessment:
            print(f"é£é™©ç­‰çº§: {result.risk_assessment.risk_level}")
            print(f"æ•´ä½“é£é™©åˆ†æ•°: {result.risk_assessment.overall_risk_score:.2f}")

        if result.trading_decision:
            print(f"äº¤æ˜“å»ºè®®: {result.trading_decision.action}")
            print(f"ä¿¡å¿ƒç­‰çº§: {result.trading_decision.conviction_level.name}")

        print(f"å…³é”®æ´å¯Ÿæ•°é‡: {len(result.key_insights)}")
        print(f"è­¦å‘Šä¿¡å·æ•°é‡: {len(result.warning_signals)}")

        return True

    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

    finally:
        llm_engine.clear_cache()
        llm_engine.clear_contexts()

async def test_partial_analysis():
    """æµ‹è¯•éƒ¨åˆ†åˆ†æåŠŸèƒ½"""
    print("\n=== æµ‹è¯•éƒ¨åˆ†åˆ†æåŠŸèƒ½ ===")

    llm_config = {'provider': 'mock', 'enable_cache': False}
    llm_engine = LLMAnalysisEngine(llm_config)

    try:
        # åªæµ‹è¯•å¸‚åœºæƒ…ç»ªåˆ†æ
        analysis_input = LLMAnalysisInput(
            symbol="ETH/USDT",
            current_price=3000.0,
            analysis_types=[AnalysisType.MARKET_SENTIMENT]
        )

        result = await llm_engine.analyze(analysis_input)

        print(f"âœ… éƒ¨åˆ†åˆ†æå®Œæˆ")
        print(f"äº¤æ˜“å¯¹: {result.symbol}")
        print(f"æ•´ä½“è¯„åˆ†: {result.overall_score:.2f}")

        if result.market_sentiment:
            print(f"æƒ…ç»ªåˆ†æ: {result.market_sentiment.overall_sentiment.name}")
        else:
            print("âš ï¸  æœªè¿”å›æƒ…ç»ªåˆ†æç»“æœ")

        # éªŒè¯å…¶ä»–åˆ†æä¸ºç©º
        if len(result.technical_explanations) == 0 and result.risk_assessment is None:
            print("âœ… å…¶ä»–åˆ†æç±»å‹æ­£ç¡®ä¸ºç©º")
        else:
            print("âŒ å…¶ä»–åˆ†æç±»å‹åº”è¯¥ä¸ºç©º")

        return True

    except Exception as e:
        print(f"âŒ éƒ¨åˆ†åˆ†ææµ‹è¯•å¤±è´¥: {e}")
        return False

    finally:
        llm_engine.clear_cache()

async def test_caching_mechanism():
    """æµ‹è¯•ç¼“å­˜æœºåˆ¶"""
    print("\n=== æµ‹è¯•ç¼“å­˜æœºåˆ¶ ===")

    llm_config = {'provider': 'mock', 'enable_cache': True, 'cache_ttl': 60}
    llm_engine = LLMAnalysisEngine(llm_config)

    try:
        analysis_input = LLMAnalysisInput(
            symbol="SOL/USDT",
            current_price=100.0,
            analysis_types=[AnalysisType.MARKET_SENTIMENT]
        )

        # ç¬¬ä¸€æ¬¡åˆ†æ
        print("æ‰§è¡Œç¬¬ä¸€æ¬¡åˆ†æ...")
        start_time = datetime.now()
        result1 = await llm_engine.analyze(analysis_input)
        first_time = (datetime.now() - start_time).total_seconds()

        # ç¬¬äºŒæ¬¡åˆ†æï¼ˆåº”è¯¥ä½¿ç”¨ç¼“å­˜ï¼‰
        print("æ‰§è¡Œç¬¬äºŒæ¬¡åˆ†æï¼ˆä½¿ç”¨ç¼“å­˜ï¼‰...")
        start_time = datetime.now()
        result2 = await llm_engine.analyze(analysis_input)
        second_time = (datetime.now() - start_time).total_seconds()

        print(f"ç¬¬ä¸€æ¬¡åˆ†ææ—¶é—´: {first_time:.3f}s")
        print(f"ç¬¬äºŒæ¬¡åˆ†ææ—¶é—´: {second_time:.3f}s")

        # éªŒè¯ç»“æœç›¸åŒ
        if result1.overall_score == result2.overall_score:
            print("âœ… ç¼“å­˜ç»“æœä¸€è‡´")
        else:
            print("âŒ ç¼“å­˜ç»“æœä¸ä¸€è‡´")

        # æ£€æŸ¥ç¼“å­˜ç»Ÿè®¡
        stats = llm_engine.get_performance_stats()
        print(f"ç¼“å­˜å¤§å°: {stats['cache_size']}")

        return True

    except Exception as e:
        print(f"âŒ ç¼“å­˜æµ‹è¯•å¤±è´¥: {e}")
        return False

    finally:
        llm_engine.clear_cache()

async def test_performance_stats():
    """æµ‹è¯•æ€§èƒ½ç»Ÿè®¡"""
    print("\n=== æµ‹è¯•æ€§èƒ½ç»Ÿè®¡ ===")

    llm_config = {'provider': 'mock', 'enable_cache': False}
    llm_engine = LLMAnalysisEngine(llm_config)

    try:
        # æ‰§è¡Œå¤šæ¬¡åˆ†æ
        analysis_input = LLMAnalysisInput(
            symbol="BNB/USDT",
            current_price=400.0,
            analysis_types=[AnalysisType.MARKET_SENTIMENT]
        )

        for i in range(3):
            await llm_engine.analyze(analysis_input)

        # è·å–æ€§èƒ½ç»Ÿè®¡
        stats = llm_engine.get_performance_stats()

        print(f"âœ… æ€§èƒ½ç»Ÿè®¡:")
        print(f"æ€»åˆ†ææ¬¡æ•°: {stats['total_analyses']}")
        print(f"æˆåŠŸåˆ†ææ¬¡æ•°: {stats['successful_analyses']}")
        print(f"å¤±è´¥åˆ†ææ¬¡æ•°: {stats['failed_analyses']}")
        print(f"æˆåŠŸç‡: {stats['success_rate']:.1%}")
        print(f"å¹³å‡å¤„ç†æ—¶é—´: {stats['avg_processing_time']:.3f}s")
        print(f"LLMæä¾›å•†: {stats['provider']}")

        return True

    except Exception as e:
        print(f"âŒ æ€§èƒ½ç»Ÿè®¡æµ‹è¯•å¤±è´¥: {e}")
        return False

    finally:
        llm_engine.clear_cache()

async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ LLMåˆ†æä¸æ¨ç†å¼•æ“æµ‹è¯•")
    print("=" * 50)

    results = []

    # åŸºæœ¬LLMåˆ†ææµ‹è¯•
    results.append(await test_basic_llm_analysis())

    # éƒ¨åˆ†åˆ†ææµ‹è¯•
    results.append(await test_partial_analysis())

    # ç¼“å­˜æœºåˆ¶æµ‹è¯•
    results.append(await test_caching_mechanism())

    # æ€§èƒ½ç»Ÿè®¡æµ‹è¯•
    results.append(await test_performance_stats())

    # è¾“å‡ºæµ‹è¯•ç»“æœ
    print("\n" + "=" * 50)
    print("æµ‹è¯•ç»“æœæ±‡æ€»:")
    passed = sum(results)
    total = len(results)
    print(f"é€šè¿‡: {passed}/{total}")

    if passed == total:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
        return 0
    else:
        print("âŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥")
        return 1

if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code)