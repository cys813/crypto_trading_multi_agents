"""
æ ¸å¿ƒåŠŸèƒ½æµ‹è¯•è„šæœ¬ - ä¸ä¾èµ–å¤–éƒ¨åº“
"""

import sys
import os
from datetime import datetime
from enum import Enum
from dataclasses import dataclass, field
from typing import Optional, Dict, Any, List
from abc import ABC, abstractmethod

# æ·»åŠ æºä»£ç è·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

# æ‰‹åŠ¨å®šä¹‰æ ¸å¿ƒæšä¸¾å’Œç±»è¿›è¡Œæµ‹è¯•
class NewsSourceStatus(Enum):
    ONLINE = "online"
    OFFLINE = "offline"
    DEGRADED = "degraded"
    MAINTENANCE = "maintenance"

class NewsCategory(Enum):
    BREAKING = "breaking"
    MARKET_ANALYSIS = "market_analysis"
    REGULATION = "regulation"
    TECHNOLOGY = "technology"
    SECURITY = "security"
    ADOPTION = "adoption"
    GENERAL = "general"

@dataclass
class NewsArticle:
    id: str
    title: str
    content: str
    summary: Optional[str] = None
    author: Optional[str] = None
    published_at: Optional[datetime] = None
    source: Optional[str] = None
    url: Optional[str] = None
    category: NewsCategory = NewsCategory.GENERAL
    tags: List[str] = field(default_factory=list)
    metadata: Dict[str, Any] = field(default_factory=dict)

@dataclass
class NewsSourceConfig:
    name: str
    adapter_type: str
    base_url: str
    api_key: Optional[str] = None
    rate_limit: int = 100
    timeout: int = 30
    headers: Dict[str, str] = field(default_factory=dict)
    enabled: bool = True
    priority: int = 1

@dataclass
class NewsQuery:
    keywords: List[str] = field(default_factory=list)
    categories: List[NewsCategory] = field(default_factory=list)
    start_date: Optional[datetime] = None
    end_date: Optional[datetime] = None
    sources: List[str] = field(default_factory=list)
    limit: int = 50
    offset: int = 0

@dataclass
class HealthStatus:
    is_healthy: bool
    response_time: float
    status: NewsSourceStatus
    last_check: datetime
    error_message: Optional[str] = None
    consecutive_failures: int = 0
    consecutive_successes: int = 0

def test_data_models():
    """æµ‹è¯•æ•°æ®æ¨¡å‹"""
    print("\n=== æµ‹è¯•æ•°æ®æ¨¡å‹ ===")

    # æµ‹è¯•æ–°é—»æ–‡ç« 
    article = NewsArticle(
        id="test_001",
        title="æ¯”ç‰¹å¸ä»·æ ¼çªç ´æ–°é«˜",
        content="æ¯”ç‰¹å¸ä»·æ ¼ä»Šæ—¥çªç ´60000ç¾å…ƒï¼Œåˆ›ä¸‹å†å²æ–°é«˜...",
        published_at=datetime.now(),
        category=NewsCategory.BREAKING,
        tags=["æ¯”ç‰¹å¸", "ä»·æ ¼", "æ–°é«˜"],
        metadata={"importance": "high"}
    )

    assert article.id == "test_001"
    assert article.title == "æ¯”ç‰¹å¸ä»·æ ¼çªç ´æ–°é«˜"
    assert article.category == NewsCategory.BREAKING
    assert "æ¯”ç‰¹å¸" in article.tags
    assert article.metadata["importance"] == "high"
    print("âœ“ NewsArticle åˆ›å»ºæˆåŠŸ")

    # æµ‹è¯•æ–°é—»æºé…ç½®
    config = NewsSourceConfig(
        name="coindesk",
        adapter_type="coindesk_adapter",
        base_url="https://api.coindesk.com/v1",
        rate_limit=60,
        timeout=30,
        enabled=True,
        priority=8,
        headers={"User-Agent": "CryptoNewsAgent/1.0"}
    )

    assert config.name == "coindesk"
    assert config.adapter_type == "coindesk_adapter"
    assert config.enabled == True
    assert config.priority == 8
    assert "User-Agent" in config.headers
    print("âœ“ NewsSourceConfig åˆ›å»ºæˆåŠŸ")

    # æµ‹è¯•æ–°é—»æŸ¥è¯¢
    query = NewsQuery(
        keywords=["æ¯”ç‰¹å¸", "ä»¥å¤ªåŠ"],
        categories=[NewsCategory.MARKET_ANALYSIS, NewsCategory.BREAKING],
        start_date=datetime(2024, 1, 1),
        end_date=datetime(2024, 12, 31),
        limit=100
    )

    assert "æ¯”ç‰¹å¸" in query.keywords
    assert len(query.categories) == 2
    assert query.limit == 100
    assert query.start_date.year == 2024
    print("âœ“ NewsQuery åˆ›å»ºæˆåŠŸ")

    # æµ‹è¯•å¥åº·çŠ¶æ€
    health = HealthStatus(
        is_healthy=True,
        response_time=150.5,
        status=NewsSourceStatus.ONLINE,
        last_check=datetime.now(),
        consecutive_successes=5
    )

    assert health.is_healthy == True
    assert health.response_time == 150.5
    assert health.status == NewsSourceStatus.ONLINE
    assert health.consecutive_successes == 5
    print("âœ“ HealthStatus åˆ›å»ºæˆåŠŸ")

def test_enum_functionality():
    """æµ‹è¯•æšä¸¾åŠŸèƒ½"""
    print("\n=== æµ‹è¯•æšä¸¾åŠŸèƒ½ ===")

    # æµ‹è¯•æ–°é—»æºçŠ¶æ€
    assert NewsSourceStatus.ONLINE.value == "online"
    assert NewsSourceStatus.OFFLINE.value == "offline"
    assert NewsSourceStatus.DEGRADED.value == "degraded"
    print("âœ“ NewsSourceStatus æšä¸¾æ­£å¸¸")

    # æµ‹è¯•æ–°é—»åˆ†ç±»
    assert NewsCategory.BREAKING.value == "breaking"
    assert NewsCategory.MARKET_ANALYSIS.value == "market_analysis"
    assert NewsCategory.TECHNOLOGY.value == "technology"
    assert NewsCategory.SECURITY.value == "security"
    print("âœ“ NewsCategory æšä¸¾æ­£å¸¸")

def test_dataclass_features():
    """æµ‹è¯•æ•°æ®ç±»ç‰¹æ€§"""
    print("\n=== æµ‹è¯•æ•°æ®ç±»ç‰¹æ€§ ===")

    # æµ‹è¯•é»˜è®¤å€¼
    default_article = NewsArticle(
        id="default_001",
        title="é»˜è®¤æ ‡é¢˜",
        content="é»˜è®¤å†…å®¹"
    )

    assert default_article.tags == []
    assert default_article.metadata == {}
    assert default_article.category == NewsCategory.GENERAL
    print("âœ“ é»˜è®¤å€¼å·¥ä½œæ­£å¸¸")

    # æµ‹è¯•ç±»å‹æç¤º
    assert isinstance(default_article.id, str)
    assert isinstance(default_article.title, str)
    assert isinstance(default_article.content, str)
    assert isinstance(default_article.tags, list)
    assert isinstance(default_article.metadata, dict)
    print("âœ“ ç±»å‹æç¤ºå·¥ä½œæ­£å¸¸")

def test_data_validation():
    """æµ‹è¯•æ•°æ®éªŒè¯é€»è¾‘"""
    print("\n=== æµ‹è¯•æ•°æ®éªŒè¯é€»è¾‘ ===")

    # æµ‹è¯•URLéªŒè¯é€»è¾‘
    def validate_url(url: str) -> bool:
        return url.startswith(('http://', 'https://'))

    valid_urls = [
        "https://api.coindesk.com/v1",
        "http://example.com/api",
        "https://cointelegraph.com/api/v1"
    ]

    invalid_urls = [
        "ftp://example.com/api",
        "api.example.com",
        "just-a-string"
    ]

    for url in valid_urls:
        assert validate_url(url), f"æœ‰æ•ˆURLè¢«æ‹’ç»: {url}"

    for url in invalid_urls:
        assert not validate_url(url), f"æ— æ•ˆURLè¢«æ¥å—: {url}"

    print("âœ“ URLéªŒè¯é€»è¾‘æ­£å¸¸")

    # æµ‹è¯•ä¼˜å…ˆçº§èŒƒå›´éªŒè¯
    def validate_priority(priority: int) -> bool:
        return 1 <= priority <= 10

    valid_priorities = [1, 5, 8, 10]
    invalid_priorities = [0, 11, -1, 15]

    for priority in valid_priorities:
        assert validate_priority(priority), f"æœ‰æ•ˆä¼˜å…ˆçº§è¢«æ‹’ç»: {priority}"

    for priority in invalid_priorities:
        assert not validate_priority(priority), f"æ— æ•ˆä¼˜å…ˆçº§è¢«æ¥å—: {priority}"

    print("âœ“ ä¼˜å…ˆçº§éªŒè¯é€»è¾‘æ­£å¸¸")

def test_business_logic():
    """æµ‹è¯•ä¸šåŠ¡é€»è¾‘"""
    print("\n=== æµ‹è¯•ä¸šåŠ¡é€»è¾‘ ===")

    # æµ‹è¯•æ–‡ç« å»é‡
    articles = [
        NewsArticle("001", "æ¯”ç‰¹å¸ä»·æ ¼ä¸Šæ¶¨", "å†…å®¹1"),
        NewsArticle("002", "æ¯”ç‰¹å¸ä»·æ ¼ä¸Šæ¶¨", "å†…å®¹2"),  # å®Œå…¨ç›¸åŒçš„æ ‡é¢˜
        NewsArticle("003", "ä»¥å¤ªåŠå‡çº§", "å†…å®¹3"),
        NewsArticle("004", "DeFiå¸‚åœºåˆ†æ", "å†…å®¹4")   # ä¸åŒçš„æ ‡é¢˜
    ]

    def deduplicate_articles(articles: List[NewsArticle]) -> List[NewsArticle]:
        seen_titles = set()
        unique_articles = []

        for article in articles:
            normalized_title = article.title.lower().strip()
            if normalized_title not in seen_titles:
                seen_titles.add(normalized_title)
                unique_articles.append(article)

        return unique_articles

    unique_articles = deduplicate_articles(articles)
    print(f"å»é‡å‰æ–‡ç« æ•°: {len(articles)}")
    print(f"å»é‡åæ–‡ç« æ•°: {len(unique_articles)}")
    print(f"å»é‡åçš„æ ‡é¢˜: {[a.title for a in unique_articles]}")

    # æ£€æŸ¥å»é‡æ˜¯å¦æ­£ç¡®ï¼ˆåº”è¯¥æœ‰3ä¸ªå”¯ä¸€æ ‡é¢˜ï¼‰
    expected_unique_count = 3
    actual_unique_count = len(unique_articles)
    assert actual_unique_count == expected_unique_count, f"å»é‡åæ•°é‡ä¸æ­£ç¡®: {actual_unique_count}, æœŸæœ›: {expected_unique_count}"

    # æ£€æŸ¥ç‰¹å®šæ ‡é¢˜æ˜¯å¦å­˜åœ¨
    titles = {article.title for article in unique_articles}
    assert "æ¯”ç‰¹å¸ä»·æ ¼ä¸Šæ¶¨" in titles
    assert "ä»¥å¤ªåŠå‡çº§" in titles
    assert "DeFiå¸‚åœºåˆ†æ" in titles
    print("âœ“ æ–‡ç« å»é‡é€»è¾‘æ­£å¸¸")

    # æµ‹è¯•æ–‡ç« åˆ†ç±»é€»è¾‘
    def categorize_by_title(title: str) -> NewsCategory:
        title_lower = title.lower()

        if any(word in title_lower for word in ['hack', 'security', 'breach', 'æ”»å‡»', 'å®‰å…¨']):
            return NewsCategory.SECURITY
        elif any(word in title_lower for word in ['price', 'market', 'trading', 'ä»·æ ¼', 'å¸‚åœº', 'äº¤æ˜“']):
            return NewsCategory.MARKET_ANALYSIS
        elif any(word in title_lower for word in ['regulation', 'law', 'government', 'ç›‘ç®¡', 'æ³•å¾‹', 'æ”¿åºœ']):
            return NewsCategory.REGULATION
        elif any(word in title_lower for word in ['tech', 'development', 'upgrade', 'æŠ€æœ¯', 'å¼€å‘', 'å‡çº§']):
            return NewsCategory.TECHNOLOGY
        elif any(word in title_lower for word in ['adoption', 'institutional', 'æŠ•èµ„', 'æœºæ„']):
            return NewsCategory.ADOPTION
        elif any(word in title_lower for word in ['breaking', 'alert', 'urgent', 'ç´§æ€¥', 'çªå‘']):
            return NewsCategory.BREAKING
        else:
            return NewsCategory.GENERAL

    test_cases = [
        ("æ¯”ç‰¹å¸ä»·æ ¼çªç ´æ–°é«˜", NewsCategory.MARKET_ANALYSIS),
        ("äº¤æ˜“æ‰€é­é‡é»‘å®¢æ”»å‡»", NewsCategory.SECURITY),
        ("ä»¥å¤ªåŠ2.0å‡çº§å®Œæˆ", NewsCategory.TECHNOLOGY),
        ("ç¾å›½ç›‘ç®¡æ–°æ”¿ç­–å‡ºå°", NewsCategory.REGULATION),
        ("æœºæ„æŠ•èµ„è€…å¤§é‡ä¹°å…¥", NewsCategory.ADOPTION),
        ("ç´§æ€¥ï¼šé‡å¤§æ–°é—»", NewsCategory.BREAKING),
        ("ä¸€èˆ¬æ€§æ–°é—»", NewsCategory.GENERAL)
    ]

    for title, expected_category in test_cases:
        result = categorize_by_title(title)
        assert result == expected_category, f"åˆ†ç±»é”™è¯¯: '{title}' -> {result}, æœŸæœ›: {expected_category}"

    print("âœ“ æ–‡ç« åˆ†ç±»é€»è¾‘æ­£å¸¸")

def test_performance_characteristics():
    """æµ‹è¯•æ€§èƒ½ç‰¹å¾"""
    print("\n=== æµ‹è¯•æ€§èƒ½ç‰¹å¾ ===")

    import time

    # æµ‹è¯•æ•°æ®åˆ›å»ºæ€§èƒ½
    start_time = time.time()

    articles = []
    for i in range(1000):
        article = NewsArticle(
            id=f"article_{i}",
            title=f"æ–°é—»æ ‡é¢˜ {i}",
            content=f"æ–°é—»å†…å®¹ {i}" * 10,
            published_at=datetime.now(),
            category=NewsCategory.GENERAL,
            tags=[f"tag_{j}" for j in range(3)]
        )
        articles.append(article)

    creation_time = time.time() - start_time
    print(f"âœ“ åˆ›å»º1000ç¯‡æ–‡ç« è€—æ—¶: {creation_time:.3f}ç§’")

    # æµ‹è¯•å»é‡æ€§èƒ½
    start_time = time.time()

    # åˆ›å»ºé‡å¤æ–‡ç« 
    duplicate_articles = []
    for i in range(500):
        duplicate_articles.extend([
            NewsArticle(f"id_{i}", f"æ ‡é¢˜_{i}", f"å†…å®¹_{i}"),
            NewsArticle(f"id_{i}_dup", f"æ ‡é¢˜_{i}", f"å†…å®¹_{i}_dup")  # ç›¸åŒæ ‡é¢˜
        ])

    def deduplicate_articles(articles: List[NewsArticle]) -> List[NewsArticle]:
        seen_titles = set()
        unique_articles = []

        for article in articles:
            normalized_title = article.title.lower().strip()
            if normalized_title not in seen_titles:
                seen_titles.add(normalized_title)
                unique_articles.append(article)

        return unique_articles

    unique_articles = deduplicate_articles(duplicate_articles)
    dedup_time = time.time() - start_time

    assert len(unique_articles) == 500
    print(f"âœ“ å»é‡1000ç¯‡æ–‡ç« è€—æ—¶: {dedup_time:.3f}ç§’")

def test_memory_usage():
    """æµ‹è¯•å†…å­˜ä½¿ç”¨"""
    print("\n=== æµ‹è¯•å†…å­˜ä½¿ç”¨ ===")

    import sys

    # æµ‹è¯•å•ä¸ªå¯¹è±¡çš„å†…å­˜å ç”¨
    article = NewsArticle(
        id="memory_test",
        title="å†…å­˜æµ‹è¯•æ–‡ç« ",
        content="è¿™æ˜¯ä¸€ç¯‡ç”¨äºæµ‹è¯•å†…å­˜ä½¿ç”¨çš„æ–‡ç« " * 100,
        tags=["å†…å­˜", "æµ‹è¯•"] * 50
    )

    article_size = sys.getsizeof(article)
    title_size = sys.getsizeof(article.title)
    content_size = sys.getsizeof(article.content)
    tags_size = sys.getsizeof(article.tags)

    print(f"âœ“ æ–‡ç« å¯¹è±¡å¤§å°: {article_size} bytes")
    print(f"âœ“ æ ‡é¢˜å¤§å°: {title_size} bytes")
    print(f"âœ“ å†…å®¹å¤§å°: {content_size} bytes")
    print(f"âœ“ æ ‡ç­¾å¤§å°: {tags_size} bytes")

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("æ–°é—»æ”¶é›†ä»£ç†æ ¸å¿ƒåŠŸèƒ½æµ‹è¯•")
    print("=" * 50)
    print(f"Pythonç‰ˆæœ¬: {sys.version}")
    print(f"æµ‹è¯•æ—¶é—´: {datetime.now()}")
    print("=" * 50)

    try:
        test_data_models()
        test_enum_functionality()
        test_dataclass_features()
        test_data_validation()
        test_business_logic()
        test_performance_characteristics()
        test_memory_usage()

        print("\n" + "=" * 50)
        print("âœ“ æ‰€æœ‰æ ¸å¿ƒæµ‹è¯•é€šè¿‡ï¼")
        print("âœ“ æ•°æ®æ¨¡å‹è®¾è®¡æ­£ç¡®")
        print("âœ“ ä¸šåŠ¡é€»è¾‘å®ç°å®Œæ•´")
        print("âœ“ æ€§èƒ½è¡¨ç°è‰¯å¥½")
        print("âœ“ å†…å­˜ä½¿ç”¨åˆç†")
        print("\nğŸ‰ æ–°é—»æ”¶é›†ä»£ç†æ¡†æ¶æ ¸å¿ƒåŠŸèƒ½å®ç°å®Œæˆï¼")

    except Exception as e:
        print(f"\nâœ— æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

if __name__ == "__main__":
    main()