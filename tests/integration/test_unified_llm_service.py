#!/usr/bin/env python3
"""
ç»Ÿä¸€LLMæœåŠ¡æµ‹è¯•

æµ‹è¯•ç»Ÿä¸€LLMæœåŠ¡æ¡†æ¶çš„åŠŸèƒ½ï¼ŒåŒ…æ‹¬ï¼š
1. LLMæœåŠ¡åˆå§‹åŒ–
2. å¤šæä¾›å•†æ”¯æŒï¼ˆDashScopeã€DeepSeekï¼‰
3. AIåˆ†ææ··å…¥ç±»
4. å„åˆ†ææ¨¡å—çš„AIå¢å¼ºåŠŸèƒ½

è¿è¡Œæ–¹å¼ï¼š
python test_unified_llm_service.py
"""

import os
import sys
import json
import logging
from typing import Dict, Any

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.dirname(__file__))

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

logger = logging.getLogger(__name__)


class MockLLMAdapter:
    """æ¨¡æ‹ŸLLMé€‚é…å™¨ï¼Œç”¨äºæµ‹è¯•"""
    
    def __init__(self, provider, model, **kwargs):
        self.provider = provider
        self.model = model
        self.kwargs = kwargs
    
    def call(self, prompt: str, **kwargs) -> str:
        """æ¨¡æ‹ŸLLMè°ƒç”¨"""
        # æ ¹æ®promptå†…å®¹è¿”å›ä¸åŒçš„æ¨¡æ‹Ÿå“åº”
        if "é“¾ä¸Šæ•°æ®åˆ†æå¸ˆ" in prompt:
            return self._get_onchain_mock_response()
        elif "æƒ…ç»ªåˆ†æå¸ˆ" in prompt:
            return self._get_sentiment_mock_response()
        elif "DeFiç”Ÿæ€åˆ†æå¸ˆ" in prompt:
            return self._get_defi_mock_response()
        elif "ç‰›å¸‚ç ”ç©¶åˆ†æå¸ˆ" in prompt:
            return self._get_bull_mock_response()
        elif "ç†Šå¸‚ç ”ç©¶åˆ†æå¸ˆ" in prompt:
            return self._get_bear_mock_response()
        else:
            return self._get_default_mock_response()
    
    def _get_onchain_mock_response(self) -> str:
        """é“¾ä¸Šåˆ†ææ¨¡æ‹Ÿå“åº”"""
        return json.dumps({
            "network_health_analysis": {
                "current_status": "å¥åº·",
                "growth_sustainability": "å¯æŒç»­",
                "network_maturity": "æˆç†ŸæœŸ",
                "development_trend": "ä¸Šå‡"
            },
            "capital_flow_analysis": {
                "exchange_flow_signal": "ç§¯ç´¯",
                "whale_behavior_impact": "çœ‹æ¶¨",
                "institutional_activity": "å¢åŠ ",
                "retail_participation": "æ´»è·ƒ"
            },
            "onchain_sentiment": {
                "overall_sentiment": "çœ‹æ¶¨",
                "sentiment_strength": 0.75,
                "divergence_signals": ["äº¤æ˜“æ‰€å‡€æµå‡º", "å·¨é²¸ç§¯ç´¯"],
                "turning_point_probability": 0.25
            },
            "investment_recommendation": {
                "timeframe": "ä¸­æœŸ",
                "recommendation": "çœ‹æ¶¨",
                "key_monitoring_metrics": ["äº¤æ˜“æ‰€ä½™é¢å˜åŒ–", "å·¨é²¸æµé‡", "ç½‘ç»œæ´»è·ƒåº¦"],
                "entry_signals": ["æŒç»­å‡€æµå‡º", "ç½‘ç»œæ´»è·ƒåº¦å¢é•¿"],
                "exit_signals": ["å¤§é‡æµå…¥äº¤æ˜“æ‰€", "ç½‘ç»œæ´»è·ƒåº¦ä¸‹é™"]
            },
            "confidence_level": 82,
            "key_insights": ["åŸºäºé“¾ä¸Šæ•°æ®åˆ†æï¼Œå½“å‰å¤„äºå¥åº·çš„ä¸Šå‡è¶‹åŠ¿ä¸­"]
        }, ensure_ascii=False)
    
    def _get_sentiment_mock_response(self) -> str:
        """æƒ…ç»ªåˆ†ææ¨¡æ‹Ÿå“åº”"""
        return json.dumps({
            "sentiment_prediction": {
                "direction": "çœ‹æ¶¨",
                "strength": 0.7,
                "duration": "ä¸­æœŸ"
            },
            "market_emotion_cycle": {
                "current_phase": "ä¹è§‚æœŸ",
                "transition_probability": 0.3,
                "cycle_maturity": "ä¸­æœŸ"
            },
            "anomaly_signals": {
                "detected": True,
                "signals": ["ææ…Œæƒ…ç»ªåè½¬", "ç¤¾äº¤åª’ä½“æƒ…ç»ªå›æš–"],
                "significance": "é«˜"
            },
            "trading_psychology": {
                "crowd_behavior": "FOMOå¼€å§‹æ˜¾ç°",
                "contrarian_value": 0.6,
                "institutional_sentiment": "è°¨æ…ä¹è§‚"
            },
            "confidence_level": 75,
            "key_insights": ["å¸‚åœºæƒ…ç»ªæ­£åœ¨ä»ææ…Œè½¬å‘ä¹è§‚", "å»ºè®®å…³æ³¨æƒ…ç»ªè¿‡çƒ­é£é™©"]
        }, ensure_ascii=False)
    
    def _get_defi_mock_response(self) -> str:
        """DeFiåˆ†ææ¨¡æ‹Ÿå“åº”"""
        return json.dumps({
            "defi_ecosystem_health": {
                "overall_health": "è‰¯å¥½",
                "growth_sustainability": "å¯æŒç»­",
                "innovation_level": "é«˜"
            },
            "protocol_risk_assessment": {
                "systemic_risk": "ä¸­",
                "smart_contract_risk": "ä½",
                "governance_risk": "ä¸­"
            },
            "tvl_analysis": {
                "trend_direction": "ä¸Šå‡",
                "sustainability_score": 0.8,
                "concentration_risk": "ä½"
            },
            "yield_sustainability": {
                "current_yields_sustainable": "å¤§éƒ¨åˆ†å¯æŒç»­",
                "risk_adjusted_return": 0.7,
                "bubble_indicators": "æ— æ˜æ˜¾æ³¡æ²«"
            },
            "confidence_level": 78,
            "key_insights": ["DeFiç”Ÿæ€æ•´ä½“å¥åº·ï¼ŒTVLå¢é•¿å¯æŒç»­"]
        }, ensure_ascii=False)
    
    def _get_bull_mock_response(self) -> str:
        """ç‰›å¸‚ç ”ç©¶æ¨¡æ‹Ÿå“åº”"""
        return json.dumps({
            "bull_momentum_score": 75,
            "market_phase_assessment": "ä¸­æœŸç‰›å¸‚",
            "strength_indicators": ["æœºæ„èµ„é‡‘æµå…¥", "æŠ€æœ¯çªç ´ç¡®è®¤", "ç›‘ç®¡æ˜ç¡®åŒ–"],
            "risk_factors": ["ä¼°å€¼è¿‡é«˜é£é™©", "ç›‘ç®¡ä¸ç¡®å®šæ€§"],
            "entry_opportunities": ["å›è°ƒæ—¶åˆ†æ‰¹å»ºä»“", "çªç ´ç¡®è®¤åè¿½æ¶¨", "æ¿å—è½®åŠ¨æœºä¼š"],
            "target_levels": {
                "short_term": 45000,
                "medium_term": 52000,
                "long_term": 65000
            },
            "confidence_level": 80,
            "key_insights": ["ç‰›å¸‚è¶‹åŠ¿ç¡®ç«‹ï¼Œå»ºè®®åˆ†æ‰¹å»ºä»“"]
        }, ensure_ascii=False)
    
    def _get_bear_mock_response(self) -> str:
        """ç†Šå¸‚ç ”ç©¶æ¨¡æ‹Ÿå“åº”"""
        return json.dumps({
            "bear_momentum_score": 65,
            "market_phase_assessment": "æ—©æœŸç†Šå¸‚",
            "weakness_indicators": ["æœºæ„èµ„é‡‘å¤–æµ", "æŠ€æœ¯å½¢æ€ç ´ä½", "å®è§‚ç¯å¢ƒæ¶åŒ–"],
            "risk_factors": ["æµåŠ¨æ€§æ¯ç«­", "ææ…Œæ€§æŠ›å”®", "ç›‘ç®¡æ‰“å‹"],
            "protection_strategies": ["å‡ä»“é¿é™©", "è®¾ç½®æ­¢æŸ", "ç°é‡‘ä¸ºç‹"],
            "support_levels": {
                "short_term": 35000,
                "medium_term": 30000,
                "long_term": 25000
            },
            "confidence_level": 72,
            "key_insights": ["ç†Šå¸‚ä¿¡å·æ˜ç¡®ï¼Œå»ºè®®é˜²å¾¡æ€§æ“ä½œ"]
        }, ensure_ascii=False)
    
    def _get_default_mock_response(self) -> str:
        """é»˜è®¤æ¨¡æ‹Ÿå“åº”"""
        return json.dumps({
            "analysis_result": "æµ‹è¯•åˆ†æç»“æœ",
            "confidence_level": 70,
            "key_insights": ["è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•å“åº”"]
        }, ensure_ascii=False)
    
    def get_info(self):
        """è·å–é€‚é…å™¨ä¿¡æ¯"""
        return {
            "provider": self.provider,
            "model": self.model,
            **self.kwargs
        }


def patch_llm_service_for_testing():
    """ä¸ºæµ‹è¯•ä¿®è¡¥LLMæœåŠ¡"""
    from src.crypto_trading_agents.services.llm_service import llm_service
    
    # æ¸…ç©ºç°æœ‰é€‚é…å™¨
    llm_service.llm_adapters = {}
    
    # æ·»åŠ æ¨¡æ‹Ÿé€‚é…å™¨
    llm_service.llm_adapters["dashscope"] = MockLLMAdapter("dashscope", "qwen-plus")
    llm_service.llm_adapters["deepseek"] = MockLLMAdapter("deepseek", "deepseek-chat")
    llm_service.default_provider = "dashscope"
    llm_service._initialized = True
    
    logger.info("LLMæœåŠ¡å·²ä¿®è¡¥ä¸ºæµ‹è¯•æ¨¡å¼")


def test_llm_service_basic_functionality():
    """æµ‹è¯•LLMæœåŠ¡åŸºæœ¬åŠŸèƒ½"""
    print("=" * 60)
    print("ğŸ”§ æµ‹è¯•LLMæœåŠ¡åŸºæœ¬åŠŸèƒ½")
    print("=" * 60)
    
    try:
        from src.crypto_trading_agents.services.llm_service import llm_service
        
        # ä¿®è¡¥æœåŠ¡ç”¨äºæµ‹è¯•
        patch_llm_service_for_testing()
        
        # æµ‹è¯•æœåŠ¡ä¿¡æ¯
        service_info = llm_service.get_service_info()
        print(f"âœ… æœåŠ¡ä¿¡æ¯: {json.dumps(service_info, ensure_ascii=False, indent=2)}")
        
        # æµ‹è¯•LLMè°ƒç”¨
        test_prompt = "ä½ æ˜¯ä¸€ä½æµ‹è¯•åˆ†æå¸ˆï¼Œè¯·åˆ†ææµ‹è¯•æ•°æ®ã€‚"
        response = llm_service.call_llm(test_prompt)
        print(f"âœ… LLMè°ƒç”¨æˆåŠŸï¼Œå“åº”é•¿åº¦: {len(response)}")
        
        # æµ‹è¯•JSONè§£æ
        parsed_result = llm_service.parse_json_response(response)
        print(f"âœ… JSONè§£ææˆåŠŸ: {type(parsed_result)}")
        
        # æµ‹è¯•æä¾›å•†åˆ‡æ¢
        response_deepseek = llm_service.call_llm(test_prompt, provider="deepseek")
        print(f"âœ… DeepSeekæä¾›å•†è°ƒç”¨æˆåŠŸï¼Œå“åº”é•¿åº¦: {len(response_deepseek)}")
        
        return True
        
    except Exception as e:
        print(f"âŒ LLMæœåŠ¡åŸºæœ¬åŠŸèƒ½æµ‹è¯•å¤±è´¥: {str(e)}")
        return False


def test_ai_analysis_mixin():
    """æµ‹è¯•AIåˆ†ææ··å…¥ç±»"""
    print("\n" + "=" * 60)
    print("ğŸ§© æµ‹è¯•AIåˆ†ææ··å…¥ç±»")
    print("=" * 60)
    
    try:
        from src.crypto_trading_agents.services.ai_analysis_mixin import StandardAIAnalysisMixin
        
        # åˆ›å»ºæµ‹è¯•ç±»
        class TestAnalyst(StandardAIAnalysisMixin):
            def __init__(self, config):
                self.config = config
                super().__init__()
            
            def _analyze_with_ai(self, traditional_analysis, raw_data):
                prompt = "æµ‹è¯•AIåˆ†æ"
                response = self.call_ai_analysis(prompt)
                return self.parse_ai_json_response(response, {"test": "default"})
            
            def _combine_analyses(self, traditional_analysis, ai_analysis):
                return self._combine_standard_analyses(traditional_analysis, ai_analysis)
        
        # æµ‹è¯•é…ç½®
        test_config = {
            "ai_analysis_config": {
                "enabled": True,
                "temperature": 0.3,
                "max_tokens": 2000
            }
        }
        
        # åˆ›å»ºæµ‹è¯•åˆ†æå¸ˆ
        analyst = TestAnalyst(test_config)
        
        # æµ‹è¯•AIåŠŸèƒ½æ£€æŸ¥
        print(f"âœ… AIå¯ç”¨çŠ¶æ€: {analyst.is_ai_enabled()}")
        
        # æµ‹è¯•AIåˆ†æä¿¡æ¯
        ai_info = analyst.get_ai_analysis_info()
        print(f"âœ… AIåˆ†æä¿¡æ¯: {ai_info['analyzer']}")
        
        # æµ‹è¯•AIå¢å¼ºåˆ†ææµç¨‹
        test_data = {"test_data": "æ ·æœ¬æ•°æ®"}
        traditional_result = {"traditional_score": 70, "confidence": 60}
        
        def mock_traditional_analyze(data):
            return traditional_result
        
        enhanced_result = analyst.analyze_with_ai_enhancement(test_data, mock_traditional_analyze)
        print(f"âœ… AIå¢å¼ºåˆ†æå®Œæˆï¼ŒåŒ…å«AIæ ‡è®°: {enhanced_result.get('ai_enhanced', False)}")
        
        return True
        
    except Exception as e:
        print(f"âŒ AIåˆ†ææ··å…¥ç±»æµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return False


def test_analyst_integration(analyst_class, analyst_name, test_data):
    """æµ‹è¯•åˆ†æå¸ˆé›†æˆ"""
    try:
        from src.crypto_trading_agents.unified_config import get_unified_config
        
        print(f"\nğŸ“Š æµ‹è¯•{analyst_name}é›†æˆ")
        print("-" * 40)
        
        # è·å–é…ç½®
        config = get_unified_config()
        
        # åˆ›å»ºåˆ†æå¸ˆ
        analyst = analyst_class(config)
        
        # æµ‹è¯•AIåŠŸèƒ½æ£€æŸ¥
        print(f"   AIå¯ç”¨çŠ¶æ€: {analyst.is_ai_enabled()}")
        
        # æ‰§è¡Œåˆ†æ
        result = analyst.analyze(test_data)
        
        # æ£€æŸ¥ç»“æœ
        if "error" in result:
            print(f"   âš ï¸  åˆ†æè¿”å›é”™è¯¯: {result['error']}")
            return False
        
        ai_enhanced = result.get('ai_enhanced', False)
        confidence = result.get('confidence', 0)
        
        print(f"   âœ… åˆ†æå®Œæˆ - AIå¢å¼º: {ai_enhanced}, ç½®ä¿¡åº¦: {confidence:.2f}")
        
        # æ£€æŸ¥AIç‰¹å®šå­—æ®µ
        ai_fields = [key for key in result.keys() if key.startswith('ai_')]
        if ai_fields:
            print(f"   ğŸ¤– AIå­—æ®µæ•°é‡: {len(ai_fields)}")
        
        return True
        
    except Exception as e:
        print(f"   âŒ {analyst_name}é›†æˆæµ‹è¯•å¤±è´¥: {str(e)}")
        return False


def test_all_analysts_integration():
    """æµ‹è¯•æ‰€æœ‰åˆ†æå¸ˆçš„é›†æˆ"""
    print("\n" + "=" * 60)
    print("ğŸ¢ æµ‹è¯•æ‰€æœ‰åˆ†æå¸ˆAIé›†æˆ")
    print("=" * 60)
    
    # ä¿®è¡¥æœåŠ¡ç”¨äºæµ‹è¯•
    patch_llm_service_for_testing()
    
    test_results = []
    
    # æµ‹è¯•OnchainAnalyst
    try:
        from src.crypto_trading_agents.agents.analysts.onchain_analyst import OnchainAnalyst
        onchain_data = {
            "active_addresses": {"daily_active": 920000},
            "transaction_metrics": {"daily_transactions": 1380000},
            "exchange_flows": {"net_flow": -3300},
            "whale_activity": {"whale_transactions": 52},
            "network_health": {"hash_rate": 520000000000000}
        }
        result = test_analyst_integration(OnchainAnalyst, "OnchainAnalyst", onchain_data)
        test_results.append(("OnchainAnalyst", result))
    except Exception as e:
        print(f"   âŒ OnchainAnalystå¯¼å…¥å¤±è´¥: {str(e)}")
        test_results.append(("OnchainAnalyst", False))
    
    # æµ‹è¯•SentimentAnalyst
    try:
        from src.crypto_trading_agents.agents.analysts.sentiment_analyst import SentimentAnalyst
        sentiment_data = {
            "twitter_sentiment": {"positive_ratio": 0.65},
            "reddit_sentiment": {"sentiment_score": 0.7},
            "fear_greed_index": {"current_value": 75},
            "news_sentiment": {"overall_sentiment": "positive"}
        }
        result = test_analyst_integration(SentimentAnalyst, "SentimentAnalyst", sentiment_data)
        test_results.append(("SentimentAnalyst", result))
    except Exception as e:
        print(f"   âŒ SentimentAnalystå¯¼å…¥å¤±è´¥: {str(e)}")
        test_results.append(("SentimentAnalyst", False))
    
    # æµ‹è¯•DefiAnalyst
    try:
        from src.crypto_trading_agents.agents.analysts.defi_analyst import DefiAnalyst
        defi_data = {
            "protocol_data": {"total_tvl": 45000000000},
            "liquidity_pools": {"top_pools": []},
            "yield_farming": {"average_apy": 12.5},
            "governance_data": {"active_proposals": 8}
        }
        result = test_analyst_integration(DefiAnalyst, "DefiAnalyst", defi_data)
        test_results.append(("DefiAnalyst", result))
    except Exception as e:
        print(f"   âŒ DefiAnalystå¯¼å…¥å¤±è´¥: {str(e)}")
        test_results.append(("DefiAnalyst", False))
    
    # æµ‹è¯•BullResearcher
    try:
        from src.crypto_trading_agents.agents.researchers.bull_researcher import BullResearcher
        bull_data = {
            "price_momentum_data": {"trend_strength": 0.8},
            "volume_analysis": {"volume_increase": 0.25},
            "institutional_flows": {"net_inflow": 1500000000},
            "technical_breakouts": {"breakout_confirmed": True}
        }
        result = test_analyst_integration(BullResearcher, "BullResearcher", bull_data)
        test_results.append(("BullResearcher", result))
    except Exception as e:
        print(f"   âŒ BullResearcherå¯¼å…¥å¤±è´¥: {str(e)}")
        test_results.append(("BullResearcher", False))
    
    # æµ‹è¯•BearResearcher
    try:
        from src.crypto_trading_agents.agents.researchers.bear_researcher import BearResearcher
        bear_data = {
            "price_decline_data": {"decline_strength": 0.7},
            "volume_analysis": {"selling_pressure": 0.6},
            "institutional_outflows": {"net_outflow": -800000000},
            "technical_breakdown": {"support_broken": True}
        }
        result = test_analyst_integration(BearResearcher, "BearResearcher", bear_data)
        test_results.append(("BearResearcher", result))
    except Exception as e:
        print(f"   âŒ BearResearcherå¯¼å…¥å¤±è´¥: {str(e)}")
        test_results.append(("BearResearcher", False))
    
    # æ±‡æ€»ç»“æœ
    successful = sum(1 for _, success in test_results if success)
    total = len(test_results)
    
    print(f"\nğŸ“ˆ åˆ†æå¸ˆé›†æˆæµ‹è¯•ç»“æœ: {successful}/{total} æˆåŠŸ")
    for name, success in test_results:
        status = "âœ…" if success else "âŒ"
        print(f"   {status} {name}")
    
    return successful == total


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ ç»Ÿä¸€LLMæœåŠ¡æµ‹è¯•å¥—ä»¶")
    print("=" * 60)
    
    test_results = []
    
    # åŸºæœ¬åŠŸèƒ½æµ‹è¯•
    test_results.append(("LLMæœåŠ¡åŸºæœ¬åŠŸèƒ½", test_llm_service_basic_functionality()))
    
    # AIåˆ†ææ··å…¥ç±»æµ‹è¯•
    test_results.append(("AIåˆ†ææ··å…¥ç±»", test_ai_analysis_mixin()))
    
    # åˆ†æå¸ˆé›†æˆæµ‹è¯•
    test_results.append(("æ‰€æœ‰åˆ†æå¸ˆé›†æˆ", test_all_analysts_integration()))
    
    # æ±‡æ€»ç»“æœ
    print("\n" + "=" * 60)
    print("ğŸ“Š æµ‹è¯•æ€»ç»“")
    print("=" * 60)
    
    successful = sum(1 for _, success in test_results if success)
    total = len(test_results)
    
    for name, success in test_results:
        status = "âœ… é€šè¿‡" if success else "âŒ å¤±è´¥"
        print(f"{status} - {name}")
    
    print(f"\nğŸ¯ æ€»ä½“æµ‹è¯•ç»“æœ: {successful}/{total} æµ‹è¯•é€šè¿‡")
    
    if successful == total:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•å‡é€šè¿‡ï¼ç»Ÿä¸€LLMæœåŠ¡é›†æˆæˆåŠŸã€‚")
        return True
    else:
        print("ğŸ”§ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦æ£€æŸ¥å’Œä¿®å¤ã€‚")
        return False


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)