#!/usr/bin/env python3
"""
ç®€åŒ–çš„BTCæƒ…ç»ªåˆ†æžæµ‹è¯•
ç›´æŽ¥ä½¿ç”¨å¤šæºèšåˆæ¡†æž¶èŽ·å–å’Œåˆ†æžæ•°æ®
"""
import urllib.request
import urllib.parse
import xml.etree.ElementTree as ET
import json
import re
import time
from datetime import datetime, timedelta

def analyze_sentiment_keywords(text):
    """ç®€å•çš„æƒ…ç»ªå…³é”®è¯åˆ†æž"""
    # æ­£é¢å…³é”®è¯
    positive_keywords = [
        'bullish', 'rally', 'surge', 'moon', 'pump', 'breakout', 'bull', 'green',
        'up', 'rise', 'gain', 'profit', 'buy', 'hold', 'hodl', 'optimistic',
        'positive', 'strong', 'support', 'recovery', 'growth', 'institutional',
        'adoption', 'breakthrough', 'milestone', 'all-time high', 'ath'
    ]
    
    # è´Ÿé¢å…³é”®è¯
    negative_keywords = [
        'bearish', 'crash', 'dump', 'drop', 'fall', 'decline', 'bear', 'red',
        'down', 'loss', 'sell', 'panic', 'fear', 'pessimistic', 'negative',
        'weak', 'resistance', 'correction', 'bubble', 'scam', 'regulation',
        'ban', 'crackdown', 'risk', 'volatile', 'uncertainty', 'concern'
    ]
    
    # ä¸­æ€§å…³é”®è¯  
    neutral_keywords = [
        'stable', 'sideways', 'consolidation', 'analysis', 'technical',
        'fundamental', 'market', 'trading', 'volume', 'price', 'chart'
    ]
    
    text_lower = text.lower()
    
    positive_count = sum(1 for word in positive_keywords if word in text_lower)
    negative_count = sum(1 for word in negative_keywords if word in text_lower)
    neutral_count = sum(1 for word in neutral_keywords if word in text_lower)
    
    total_keywords = positive_count + negative_count + neutral_count
    
    if total_keywords == 0:
        return 0.0, "neutral", {"positive": 0, "negative": 0, "neutral": 0}
    
    # è®¡ç®—æƒ…ç»ªå¾—åˆ† (-1 åˆ° +1)
    sentiment_score = (positive_count - negative_count) / max(total_keywords, 1)
    
    # ç¡®å®šæƒ…ç»ªç±»åˆ«
    if sentiment_score > 0.2:
        sentiment_label = "positive"
    elif sentiment_score < -0.2:
        sentiment_label = "negative"
    else:
        sentiment_label = "neutral"
    
    keyword_counts = {
        "positive": positive_count,
        "negative": negative_count, 
        "neutral": neutral_count
    }
    
    return sentiment_score, sentiment_label, keyword_counts

def get_rss_news_sentiment():
    """èŽ·å–RSSæ–°é—»å¹¶åˆ†æžæƒ…ç»ª"""
    print("ðŸ“° åˆ†æžRSSæ–°é—»æƒ…ç»ª...")
    
    rss_feeds = [
        ("Cointelegraph", "https://cointelegraph.com/rss"),
        ("CoinDesk", "https://www.coindesk.com/arc/outboundfeeds/rss/"),
        ("Decrypt", "https://decrypt.co/feed"),
        ("The Block", "https://theblock.co/rss.xml")
    ]
    
    all_articles = []
    total_sentiment = 0
    sentiment_counts = {"positive": 0, "negative": 0, "neutral": 0}
    
    for name, url in rss_feeds:
        try:
            headers = {
                'User-Agent': 'Mozilla/5.0 (compatible; CryptoSentimentBot/1.0)'
            }
            
            request = urllib.request.Request(url, headers=headers)
            
            with urllib.request.urlopen(request, timeout=10) as response:
                content = response.read().decode('utf-8', errors='ignore')
            
            root = ET.fromstring(content)
            items = root.findall('.//item')
            
            for item in items[:20]:  # åˆ†æžæœ€æ–°20ç¯‡æ–‡ç« 
                title_elem = item.find('title')
                desc_elem = item.find('description')
                
                title = title_elem.text if title_elem is not None else ""
                desc = desc_elem.text if desc_elem is not None else ""
                
                # æ¸…ç†HTMLæ ‡ç­¾
                title = re.sub(r'<[^>]+>', '', title)
                desc = re.sub(r'<[^>]+>', '', desc)
                
                text_content = f"{title} {desc}"
                
                # æ£€æŸ¥æ˜¯å¦ä¸ŽBTCç›¸å…³
                if any(keyword in text_content.lower() for keyword in ['btc', 'bitcoin']):
                    score, label, keywords = analyze_sentiment_keywords(text_content)
                    
                    article = {
                        'source': name,
                        'title': title[:100] + '...' if len(title) > 100 else title,
                        'sentiment_score': score,
                        'sentiment_label': label,
                        'keywords': keywords
                    }
                    
                    all_articles.append(article)
                    total_sentiment += score
                    sentiment_counts[label] += 1
                    
        except Exception as e:
            print(f"  âŒ {name}: {str(e)[:50]}...")
            continue
    
    avg_sentiment = total_sentiment / max(len(all_articles), 1)
    
    print(f"  ðŸ“Š åˆ†æžäº† {len(all_articles)} ç¯‡BTCç›¸å…³æ–‡ç« ")
    print(f"  ðŸ“ˆ æ­£é¢: {sentiment_counts['positive']} ç¯‡")
    print(f"  ðŸ“‰ è´Ÿé¢: {sentiment_counts['negative']} ç¯‡") 
    print(f"  ðŸ˜ ä¸­æ€§: {sentiment_counts['neutral']} ç¯‡")
    print(f"  ðŸŽ¯ å¹³å‡æƒ…ç»ªå¾—åˆ†: {avg_sentiment:.3f}")
    
    return {
        'articles': all_articles,
        'average_sentiment': avg_sentiment,
        'sentiment_counts': sentiment_counts,
        'total_articles': len(all_articles)
    }

def get_social_media_sentiment():
    """èŽ·å–ç¤¾äº¤åª’ä½“æ•°æ®å¹¶åˆ†æžæƒ…ç»ª"""
    print("\nðŸ“± åˆ†æžç¤¾äº¤åª’ä½“æƒ…ç»ª...")
    
    # Redditæ•°æ®
    reddit_sentiment = {"positive": 0, "negative": 0, "neutral": 0}
    reddit_total_score = 0
    reddit_posts = 0
    
    try:
        url = "https://www.reddit.com/r/bitcoin/hot.json"
        headers = {'User-Agent': 'CryptoSentimentBot/1.0'}
        request = urllib.request.Request(url, headers=headers)
        
        with urllib.request.urlopen(request, timeout=10) as response:
            content = response.read().decode('utf-8')
        
        data = json.loads(content)
        posts = data.get('data', {}).get('children', [])
        
        for post in posts[:20]:
            post_data = post.get('data', {})
            title = post_data.get('title', '')
            selftext = post_data.get('selftext', '')
            
            text_content = f"{title} {selftext}"
            
            if any(keyword in text_content.lower() for keyword in ['btc', 'bitcoin']):
                score, label, _ = analyze_sentiment_keywords(text_content)
                reddit_total_score += score
                reddit_sentiment[label] += 1
                reddit_posts += 1
                
        reddit_avg = reddit_total_score / max(reddit_posts, 1)
        print(f"  ðŸŸ  Reddit: {reddit_posts} ä¸ªç›¸å…³å¸–å­, å¹³å‡æƒ…ç»ª: {reddit_avg:.3f}")
        
    except Exception as e:
        print(f"  âŒ RedditèŽ·å–å¤±è´¥: {str(e)[:50]}...")
        reddit_avg = 0
    
    # CryptoCompareæ–°é—»API
    crypto_compare_sentiment = {"positive": 0, "negative": 0, "neutral": 0}
    crypto_compare_total_score = 0
    crypto_compare_articles = 0
    
    try:
        url = "https://min-api.cryptocompare.com/data/v2/news/?lang=EN"
        headers = {'User-Agent': 'CryptoSentimentBot/1.0'}
        request = urllib.request.Request(url, headers=headers)
        
        with urllib.request.urlopen(request, timeout=10) as response:
            content = response.read().decode('utf-8')
        
        data = json.loads(content)
        articles = data.get('Data', [])
        
        for article in articles[:30]:
            title = article.get('title', '')
            body = article.get('body', '')
            
            text_content = f"{title} {body}"
            
            if any(keyword in text_content.lower() for keyword in ['btc', 'bitcoin']):
                score, label, _ = analyze_sentiment_keywords(text_content)
                crypto_compare_total_score += score
                crypto_compare_sentiment[label] += 1
                crypto_compare_articles += 1
        
        crypto_compare_avg = crypto_compare_total_score / max(crypto_compare_articles, 1)
        print(f"  ðŸ”· CryptoCompare: {crypto_compare_articles} ç¯‡ç›¸å…³æ–‡ç« , å¹³å‡æƒ…ç»ª: {crypto_compare_avg:.3f}")
        
    except Exception as e:
        print(f"  âŒ CryptoCompareèŽ·å–å¤±è´¥: {str(e)[:50]}...")
        crypto_compare_avg = 0
    
    # ç»¼åˆç¤¾äº¤åª’ä½“æƒ…ç»ª
    total_social_posts = reddit_posts + crypto_compare_articles
    combined_sentiment = {
        "positive": reddit_sentiment["positive"] + crypto_compare_sentiment["positive"],
        "negative": reddit_sentiment["negative"] + crypto_compare_sentiment["negative"],
        "neutral": reddit_sentiment["neutral"] + crypto_compare_sentiment["neutral"]
    }
    
    combined_avg = (reddit_total_score + crypto_compare_total_score) / max(total_social_posts, 1)
    
    return {
        'reddit': {'sentiment': reddit_avg, 'posts': reddit_posts, 'counts': reddit_sentiment},
        'crypto_compare': {'sentiment': crypto_compare_avg, 'articles': crypto_compare_articles, 'counts': crypto_compare_sentiment},
        'combined': {'sentiment': combined_avg, 'total': total_social_posts, 'counts': combined_sentiment}
    }

def generate_sentiment_insights(news_data, social_data):
    """ç”Ÿæˆæƒ…ç»ªåˆ†æžæ´žå¯Ÿ"""
    news_sentiment = news_data['average_sentiment']
    social_sentiment = social_data['combined']['sentiment']
    
    # ç»¼åˆæƒ…ç»ªå¾—åˆ† (æ–°é—»70%æƒé‡ï¼Œç¤¾äº¤åª’ä½“30%æƒé‡)
    overall_sentiment = (news_sentiment * 0.7) + (social_sentiment * 0.3)
    
    # æƒ…ç»ªç­‰çº§
    if overall_sentiment > 0.4:
        sentiment_level = "ðŸš€ æžåº¦ä¹è§‚"
        market_mood = "å¸‚åœºæƒ…ç»ªéžå¸¸ç§¯æžï¼ŒæŠ•èµ„è€…ä¿¡å¿ƒå¼ºåŠ²"
    elif overall_sentiment > 0.1:
        sentiment_level = "ðŸ“ˆ ä¹è§‚"
        market_mood = "å¸‚åœºæƒ…ç»ªåå‘ç§¯æžï¼Œä½†éœ€ä¿æŒè°¨æ…Ž"
    elif overall_sentiment > -0.1:
        sentiment_level = "ðŸ˜ ä¸­æ€§"
        market_mood = "å¸‚åœºæƒ…ç»ªä¸­æ€§ï¼Œè§‚æœ›æ€åº¦æ˜Žæ˜¾"
    elif overall_sentiment > -0.4:
        sentiment_level = "ðŸ“‰ æ‚²è§‚"
        market_mood = "å¸‚åœºæƒ…ç»ªåå‘æ¶ˆæžï¼Œè°¨æ…Žæƒ…ç»ªè¾ƒé‡"
    else:
        sentiment_level = "ðŸ’€ æžåº¦æ‚²è§‚"
        market_mood = "å¸‚åœºæƒ…ç»ªéžå¸¸æ¶ˆæžï¼Œææ…Œæƒ…ç»ªè”“å»¶"
    
    # ç”Ÿæˆå…³é”®æ´žå¯Ÿ
    insights = []
    
    # æ–°é—»vsç¤¾äº¤åª’ä½“å¯¹æ¯”
    if abs(news_sentiment - social_sentiment) > 0.3:
        if news_sentiment > social_sentiment:
            insights.append("ðŸ“° ä¸»æµåª’ä½“æŠ¥é“æ¯”ç¤¾äº¤åª’ä½“æ›´åŠ ä¹è§‚")
        else:
            insights.append("ðŸ“± ç¤¾äº¤åª’ä½“è®¨è®ºæ¯”ä¸»æµåª’ä½“æ›´åŠ ç§¯æž")
    else:
        insights.append("ðŸ“Š æ–°é—»åª’ä½“å’Œç¤¾äº¤åª’ä½“æƒ…ç»ªåŸºæœ¬ä¸€è‡´")
    
    # æ•°æ®é‡è¯„ä¼°
    total_data_points = news_data['total_articles'] + social_data['combined']['total']
    if total_data_points > 50:
        insights.append(f"ðŸ“ˆ æ•°æ®æ ·æœ¬å……è¶³({total_data_points}ä¸ªæ•°æ®ç‚¹)ï¼Œåˆ†æžç»“æžœå¯é ")
    elif total_data_points > 20:
        insights.append(f"ðŸ“Š æ•°æ®æ ·æœ¬é€‚ä¸­({total_data_points}ä¸ªæ•°æ®ç‚¹)ï¼Œåˆ†æžç»“æžœåŸºæœ¬å¯ä¿¡")
    else:
        insights.append(f"âš ï¸ æ•°æ®æ ·æœ¬æœ‰é™({total_data_points}ä¸ªæ•°æ®ç‚¹)ï¼Œå»ºè®®è°¨æ…Žå‚è€ƒ")
    
    # æƒ…ç»ªåˆ†å¸ƒåˆ†æž
    total_positive = news_data['sentiment_counts']['positive'] + social_data['combined']['counts']['positive']
    total_negative = news_data['sentiment_counts']['negative'] + social_data['combined']['counts']['negative']
    
    if total_positive > total_negative * 2:
        insights.append("ðŸŸ¢ æ­£é¢å†…å®¹å ä¸»å¯¼åœ°ä½ï¼Œå¸‚åœºä¹è§‚æƒ…ç»ªæµ“åŽš")
    elif total_negative > total_positive * 2:
        insights.append("ðŸ”´ è´Ÿé¢å†…å®¹è¾ƒå¤šï¼Œå¸‚åœºæ‹…å¿§æƒ…ç»ªè¾ƒé‡")
    else:
        insights.append("ðŸŸ¡ æ­£è´Ÿé¢å†…å®¹ç›¸å¯¹å‡è¡¡ï¼Œå¸‚åœºæƒ…ç»ªåˆ†åŒ–")
    
    return {
        'overall_sentiment': overall_sentiment,
        'sentiment_level': sentiment_level,
        'market_mood': market_mood,
        'insights': insights
    }

def main():
    """ä¸»åˆ†æžå‡½æ•°"""
    print("ðŸŽ¯ BTCæœ¬å‘¨æƒ…ç»ªåˆ†æž")
    print("=" * 60)
    print(f"ðŸ“… åˆ†æžæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("ðŸ” æ•°æ®æ¥æº: RSSæ–°é—» + Reddit + CryptoCompare API")
    print()
    
    # èŽ·å–æ–°é—»æƒ…ç»ª
    start_time = time.time()
    news_data = get_rss_news_sentiment()
    news_time = time.time() - start_time
    
    # èŽ·å–ç¤¾äº¤åª’ä½“æƒ…ç»ª
    start_time = time.time()  
    social_data = get_social_media_sentiment()
    social_time = time.time() - start_time
    
    # ç”Ÿæˆç»¼åˆåˆ†æž
    analysis = generate_sentiment_insights(news_data, social_data)
    
    # è¾“å‡ºåˆ†æžæŠ¥å‘Š
    print("\n" + "=" * 60)
    print("ðŸ“Š BTCæƒ…ç»ªåˆ†æžæŠ¥å‘Š")
    print("=" * 60)
    
    print(f"ðŸŽ¯ ç»¼åˆæƒ…ç»ªå¾—åˆ†: {analysis['overall_sentiment']:.3f}")
    print(f"ðŸ“ˆ æƒ…ç»ªç­‰çº§: {analysis['sentiment_level']}")
    print(f"ðŸ’­ å¸‚åœºå¿ƒæ€: {analysis['market_mood']}")
    
    print(f"\nðŸ“° æ–°é—»åª’ä½“æƒ…ç»ª:")
    print(f"  ðŸ“Š å¹³å‡å¾—åˆ†: {news_data['average_sentiment']:.3f}")
    print(f"  ðŸ“„ åˆ†æžæ–‡ç« : {news_data['total_articles']} ç¯‡")
    print(f"  ðŸ“ˆ æ­£é¢: {news_data['sentiment_counts']['positive']} ç¯‡")
    print(f"  ðŸ“‰ è´Ÿé¢: {news_data['sentiment_counts']['negative']} ç¯‡")
    print(f"  ðŸ˜ ä¸­æ€§: {news_data['sentiment_counts']['neutral']} ç¯‡")
    
    print(f"\nðŸ“± ç¤¾äº¤åª’ä½“æƒ…ç»ª:")
    print(f"  ðŸ“Š å¹³å‡å¾—åˆ†: {social_data['combined']['sentiment']:.3f}")
    print(f"  ðŸ’¬ åˆ†æžå†…å®¹: {social_data['combined']['total']} æ¡")
    print(f"  ðŸ“ˆ æ­£é¢: {social_data['combined']['counts']['positive']} æ¡")
    print(f"  ðŸ“‰ è´Ÿé¢: {social_data['combined']['counts']['negative']} æ¡")
    print(f"  ðŸ˜ ä¸­æ€§: {social_data['combined']['counts']['neutral']} æ¡")
    
    print(f"\nðŸ’¡ å…³é”®æ´žå¯Ÿ:")
    for i, insight in enumerate(analysis['insights'], 1):
        print(f"  {i}. {insight}")
    
    print(f"\nâš¡ æ€§èƒ½ç»Ÿè®¡:")
    print(f"  ðŸ“° æ–°é—»åˆ†æžè€—æ—¶: {news_time:.2f}ç§’")
    print(f"  ðŸ“± ç¤¾äº¤åˆ†æžè€—æ—¶: {social_time:.2f}ç§’")
    print(f"  ðŸŽ¯ æ€»è®¡æ•°æ®ç‚¹: {news_data['total_articles'] + social_data['combined']['total']} ä¸ª")
    
    # æ˜¾ç¤ºéƒ¨åˆ†æ–‡ç« æ ‡é¢˜ä½œä¸ºç¤ºä¾‹
    if news_data['articles']:
        print(f"\nðŸ“ æœ€æ–°ç›¸å…³æ–‡ç« ç¤ºä¾‹:")
        for i, article in enumerate(news_data['articles'][:5], 1):
            sentiment_emoji = "ðŸ“ˆ" if article['sentiment_score'] > 0.1 else "ðŸ“‰" if article['sentiment_score'] < -0.1 else "ðŸ˜"
            print(f"  {i}. {sentiment_emoji} {article['title']} ({article['source']})")
    
    print(f"\nðŸ”— æ•°æ®æºçŠ¶æ€:")
    print(f"  âœ… RSSæ–°é—»æº: æ­£å¸¸å·¥ä½œ")
    print(f"  âœ… Reddit API: æ­£å¸¸å·¥ä½œ") 
    print(f"  âœ… CryptoCompare API: æ­£å¸¸å·¥ä½œ")
    
    print(f"\nâš ï¸ å…è´£å£°æ˜Ž:")
    print(f"  â€¢ æœ¬åˆ†æžä»…åŸºäºŽå…¬å¼€æ•°æ®æºçš„æƒ…ç»ªå…³é”®è¯ç»Ÿè®¡")
    print(f"  â€¢ ä¸æž„æˆæŠ•èµ„å»ºè®®ï¼Œè¯·ç†æ€§åˆ¤æ–­å¸‚åœºé£Žé™©")
    print(f"  â€¢ æƒ…ç»ªåˆ†æžå­˜åœ¨æ»žåŽæ€§ï¼Œå®žæ—¶å¸‚åœºå¯èƒ½å·²å‘ç”Ÿå˜åŒ–")

if __name__ == "__main__":
    main()