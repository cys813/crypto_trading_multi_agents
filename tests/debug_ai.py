#!/usr/bin/env python3
"""
è¯Šæ–­AIåˆ†æåŠŸèƒ½ä¸ºä»€ä¹ˆæ²¡æœ‰å·¥ä½œ
"""
import sys
import os
sys.path.insert(0, './src')

from crypto_trading_agents.default_config import DEFAULT_CONFIG
from crypto_trading_agents.unified_config import get_unified_config
from crypto_trading_agents.services.llm_service import llm_service, is_llm_service_available
import os

def diagnose_ai_setup():
    """è¯Šæ–­AIè®¾ç½®"""
    print('ğŸ” è¯Šæ–­AIåˆ†æåŠŸèƒ½è®¾ç½®...')
    print('=' * 60)

    # 1. æ£€æŸ¥ç¯å¢ƒå˜é‡
    print('1. ç¯å¢ƒå˜é‡æ£€æŸ¥:')
    dashscope_key = os.getenv('DASHSCOPE_API_KEY')
    deepseek_key = os.getenv('DEEPSEEK_API_KEY')
    openai_key = os.getenv('OPENAI_API_KEY')

    print(f'   DASHSCOPE_API_KEY: {"âœ… å·²è®¾ç½®" if dashscope_key else "âŒ æœªè®¾ç½®"}')
    print(f'   DEEPSEEK_API_KEY: {"âœ… å·²è®¾ç½®" if deepseek_key else "âŒ æœªè®¾ç½®"}')
    print(f'   OPENAI_API_KEY: {"âœ… å·²è®¾ç½®" if openai_key else "âŒ æœªè®¾ç½®"}')

    # 2. æ£€æŸ¥LLMæœåŠ¡çŠ¶æ€
    print('\n2. LLMæœåŠ¡çŠ¶æ€:')
    print(f'   LLMæœåŠ¡å¯ç”¨æ€§: {"âœ… å¯ç”¨" if is_llm_service_available() else "âŒ ä¸å¯ç”¨"}')
    print(f'   å·²åˆå§‹åŒ–é€‚é…å™¨æ•°: {len(llm_service.llm_adapters)}')
    if llm_service.llm_adapters:
        print(f'   å¯ç”¨é€‚é…å™¨: {list(llm_service.llm_adapters.keys())}')
        print(f'   é»˜è®¤æä¾›è€…: {llm_service.default_provider}')
    else:
        print('   æ²¡æœ‰å¯ç”¨çš„LLMé€‚é…å™¨')

    # 3. æ£€æŸ¥é…ç½®
    print('\n3. é…ç½®æ£€æŸ¥:')
    # è·å–ç»Ÿä¸€é…ç½®
    unified_config = get_unified_config()
    print(f'   ç»Ÿä¸€é…ç½®AIå¯ç”¨: {unified_config.get("ai_analysis_config", {}).get("enabled", False)}')

    # æ£€æŸ¥é»˜è®¤é…ç½®ä¸­çš„LLMç›¸å…³è®¾ç½®
    llm_provider = DEFAULT_CONFIG.get('llm_provider', 'æœªè®¾ç½®')
    deep_think_llm = DEFAULT_CONFIG.get('deep_think_llm', 'æœªè®¾ç½®')
    quick_think_llm = DEFAULT_CONFIG.get('quick_think_llm', 'æœªè®¾ç½®')
    print(f'   LLMæä¾›è€…: {llm_provider}')
    print(f'   æ·±åº¦æ€è€ƒæ¨¡å‹: {deep_think_llm}')
    print(f'   å¿«é€Ÿæ€è€ƒæ¨¡å‹: {quick_think_llm}')

    # 4. æ£€æŸ¥LLMæœåŠ¡é…ç½®
    llm_service_config = unified_config.get('llm_service_config')
    if llm_service_config:
        print('\n4. LLMæœåŠ¡é…ç½®è¯¦æƒ…:')
        print(f'   é»˜è®¤æä¾›è€…: {llm_service_config.get("default_provider", "æœªè®¾ç½®")}')
        providers = llm_service_config.get('providers', {})
        print(f'   é…ç½®çš„æä¾›è€…: {list(providers.keys())}')
        for provider, config in providers.items():
            api_key = config.get('api_key')
            model = config.get('model', 'æœªè®¾ç½®')
            has_key = api_key and api_key.strip() != ''
            print(f'   - {provider}: APIå¯†é’¥{"âœ…" if has_key else "âŒ"}, æ¨¡å‹: {model}')
    else:
        print('\n4. æœªæ‰¾åˆ°LLMæœåŠ¡é…ç½®')

    print('\n' + '=' * 60)
    print('è¯Šæ–­å®Œæˆ')

if __name__ == "__main__":
    diagnose_ai_setup()