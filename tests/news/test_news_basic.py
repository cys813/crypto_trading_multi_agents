#!/usr/bin/env python3
"""
ä½¿ç”¨Pythonæ ‡å‡†åº“æµ‹è¯•æ–°é—»æºè·å–èƒ½åŠ›
ä¸éœ€è¦å®‰è£…é¢å¤–ä¾èµ–
"""
import urllib.request
import urllib.parse
import xml.etree.ElementTree as ET
import json
import re
import time
from datetime import datetime

def test_rss_feeds_basic():
    """ä½¿ç”¨æ ‡å‡†åº“æµ‹è¯•RSS feeds"""
    print("=== RSS Feeds åŸºç¡€æµ‹è¯• ===")
    
    rss_feeds = [
        ("Cointelegraph", "https://cointelegraph.com/rss"),
        ("CoinDesk", "https://www.coindesk.com/arc/outboundfeeds/rss/"),
        ("Decrypt", "https://decrypt.co/feed"),
        ("The Block", "https://theblock.co/rss.xml"),
        ("CryptoSlate", "https://cryptoslate.com/feed/"),
    ]
    
    total_articles = 0
    currency_keywords = ['btc', 'bitcoin', 'crypto', 'cryptocurrency', 'blockchain']
    
    for name, url in rss_feeds:
        print(f"\nğŸ“° æµ‹è¯• {name}")
        try:
            # è®¾ç½®è¯·æ±‚å¤´
            headers = {
                'User-Agent': 'Mozilla/5.0 (compatible; NewsBot/1.0)',
                'Accept': 'application/rss+xml, application/xml, text/xml'
            }
            
            # åˆ›å»ºè¯·æ±‚
            request = urllib.request.Request(url, headers=headers)
            
            start_time = time.time()
            with urllib.request.urlopen(request, timeout=15) as response:
                content = response.read().decode('utf-8', errors='ignore')
            elapsed_time = time.time() - start_time
            
            # è§£æXML
            try:
                root = ET.fromstring(content)
            except ET.ParseError as e:
                print(f"  âŒ XMLè§£æé”™è¯¯: {str(e)[:50]}...")
                continue
            
            # æŸ¥æ‰¾æ–‡ç« é¡¹ç›®
            items = []
            
            # RSS 2.0 æ ¼å¼
            rss_items = root.findall('.//item')
            if rss_items:
                items = rss_items
            else:
                # Atom æ ¼å¼
                atom_entries = root.findall('.//{http://www.w3.org/2005/Atom}entry')
                if atom_entries:
                    items = atom_entries
            
            if items:
                relevant_count = 0
                total_count = len(items)
                
                # æ£€æŸ¥ç›¸å…³æ–‡ç« 
                for item in items[:50]:  # æ£€æŸ¥å‰50ä¸ªé¡¹ç›®
                    title_elem = item.find('title')
                    desc_elem = item.find('description') or item.find('{http://www.w3.org/2005/Atom}summary')
                    
                    title = title_elem.text if title_elem is not None and title_elem.text else ""
                    desc = desc_elem.text if desc_elem is not None and desc_elem.text else ""
                    
                    # æ¸…ç†HTMLæ ‡ç­¾
                    title = re.sub(r'<[^>]+>', '', title)
                    desc = re.sub(r'<[^>]+>', '', desc)
                    
                    text_content = f"{title} {desc}".lower()
                    
                    if any(keyword in text_content for keyword in currency_keywords):
                        relevant_count += 1
                
                print(f"  âœ… æˆåŠŸè·å–")
                print(f"  ğŸ“„ æ€»æ–‡ç« æ•°: {total_count}")
                print(f"  ğŸ¯ åŠ å¯†è´§å¸ç›¸å…³: {relevant_count} ç¯‡")
                print(f"  â±ï¸ å“åº”æ—¶é—´: {elapsed_time:.2f}ç§’")
                
                # æ˜¾ç¤ºæœ€æ–°æ ‡é¢˜ç¤ºä¾‹
                if relevant_count > 0:
                    print(f"  ğŸ“ ç¤ºä¾‹æ ‡é¢˜:")
                    count = 0
                    for item in items[:20]:
                        if count >= 2:
                            break
                        title_elem = item.find('title')
                        if title_elem is not None and title_elem.text:
                            title = re.sub(r'<[^>]+>', '', title_elem.text)
                            if any(keyword in title.lower() for keyword in currency_keywords):
                                title = title[:70] + '...' if len(title) > 70 else title
                                print(f"     â€¢ {title}")
                                count += 1
                
                total_articles += relevant_count
            else:
                print(f"  âš ï¸ æœªæ‰¾åˆ°æ–‡ç« é¡¹ç›®")
                
        except urllib.error.HTTPError as e:
            print(f"  âŒ HTTPé”™è¯¯ {e.code}: {e.reason}")
        except urllib.error.URLError as e:
            print(f"  âŒ è¿æ¥é”™è¯¯: {str(e)}")
        except Exception as e:
            print(f"  âŒ å…¶ä»–é”™è¯¯: {str(e)[:50]}...")
    
    print(f"\nğŸ”¢ RSS Feeds æ€»ç»“:")
    print(f"   æ€»è®¡åŠ å¯†è´§å¸ç›¸å…³æ–‡ç« : {total_articles} ç¯‡")
    return total_articles

def test_web_pages_basic():
    """æµ‹è¯•åŸºæœ¬ç½‘é¡µå†…å®¹è·å–"""
    print("\n=== ç½‘é¡µå†…å®¹åŸºç¡€æµ‹è¯• ===")
    
    urls = [
        ("CoinDesk Bitcoiné¡µé¢", "https://www.coindesk.com/tag/bitcoin/"),
        ("Cointelegraph", "https://cointelegraph.com/"),
    ]
    
    total_content = 0
    
    for name, url in urls:
        print(f"\nğŸŒ æµ‹è¯• {name}")
        try:
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
            }
            
            request = urllib.request.Request(url, headers=headers)
            
            start_time = time.time()
            with urllib.request.urlopen(request, timeout=15) as response:
                content = response.read().decode('utf-8', errors='ignore')
            elapsed_time = time.time() - start_time
            
            # ç®€å•åˆ†æé¡µé¢å†…å®¹
            bitcoin_mentions = len(re.findall(r'\bbitcoin\b', content, re.IGNORECASE))
            crypto_mentions = len(re.findall(r'\bcrypt[o|a]\w*', content, re.IGNORECASE))
            btc_mentions = len(re.findall(r'\bbtc\b', content, re.IGNORECASE))
            
            # å¯»æ‰¾å¯èƒ½çš„æ ‡é¢˜
            title_patterns = [
                r'<h[1-3][^>]*>([^<]+)</h[1-3]>',
                r'<title[^>]*>([^<]+)</title>',
                r'"title":\s*"([^"]+)"'
            ]
            
            titles_found = []
            for pattern in title_patterns:
                matches = re.findall(pattern, content, re.IGNORECASE)
                titles_found.extend(matches)
                if len(titles_found) >= 10:
                    break
            
            print(f"  âœ… é¡µé¢åŠ è½½æˆåŠŸ")
            print(f"  ğŸ“„ é¡µé¢å¤§å°: {len(content):,} å­—ç¬¦")
            print(f"  ğŸ” BitcoinæåŠ: {bitcoin_mentions} æ¬¡")
            print(f"  ğŸ” Cryptoç›¸å…³: {crypto_mentions} æ¬¡")
            print(f"  ğŸ” BTCæåŠ: {btc_mentions} æ¬¡")
            print(f"  ğŸ“ æ‰¾åˆ°æ ‡é¢˜: {len(titles_found)} ä¸ª")
            print(f"  â±ï¸ å“åº”æ—¶é—´: {elapsed_time:.2f}ç§’")
            
            # æ˜¾ç¤ºä¸€äº›æ ‡é¢˜ç¤ºä¾‹
            if titles_found:
                print(f"  ğŸ“° æ ‡é¢˜ç¤ºä¾‹:")
                for i, title in enumerate(titles_found[:3], 1):
                    clean_title = re.sub(r'[^\w\s-]', '', title).strip()
                    if len(clean_title) > 10:
                        clean_title = clean_title[:60] + '...' if len(clean_title) > 60 else clean_title
                        print(f"     {i}. {clean_title}")
            
            total_content += bitcoin_mentions + crypto_mentions + btc_mentions
            
        except Exception as e:
            print(f"  âŒ è·å–å¤±è´¥: {str(e)[:50]}...")
    
    print(f"\nğŸ”¢ ç½‘é¡µå†…å®¹æ€»ç»“:")
    print(f"   æ€»è®¡åŠ å¯†è´§å¸ç›¸å…³å†…å®¹: {total_content} ä¸ªæåŠ")
    return total_content

def test_json_apis():
    """æµ‹è¯•ä¸€äº›æä¾›JSONæ•°æ®çš„å…è´¹API"""
    print("\n=== JSON API åŸºç¡€æµ‹è¯• ===")
    
    apis = [
        ("CoinGeckoæ–°é—»", "https://api.coingecko.com/api/v3/news"),
        ("CryptoCompareæ–°é—»", "https://min-api.cryptocompare.com/data/v2/news/?lang=EN")
    ]
    
    total_articles = 0
    
    for name, url in apis:
        print(f"\nğŸ”— æµ‹è¯• {name}")
        try:
            headers = {
                'User-Agent': 'Mozilla/5.0 (compatible; CryptoBot/1.0)',
                'Accept': 'application/json'
            }
            
            request = urllib.request.Request(url, headers=headers)
            
            start_time = time.time()
            with urllib.request.urlopen(request, timeout=15) as response:
                content = response.read().decode('utf-8')
            elapsed_time = time.time() - start_time
            
            # è§£æJSON
            data = json.loads(content)
            
            article_count = 0
            if isinstance(data, dict):
                if 'Data' in data and isinstance(data['Data'], list):
                    # CryptoCompareæ ¼å¼
                    article_count = len(data['Data'])
                    articles = data['Data']
                elif 'data' in data and isinstance(data['data'], list):
                    # å…¶ä»–æ ¼å¼
                    article_count = len(data['data'])
                    articles = data['data']
                elif isinstance(data.get('results'), list):
                    article_count = len(data['results'])
                    articles = data['results']
                else:
                    articles = []
            elif isinstance(data, list):
                article_count = len(data)
                articles = data
            else:
                articles = []
            
            print(f"  âœ… APIå“åº”æˆåŠŸ")
            print(f"  ğŸ“„ è·å–æ–‡ç« : {article_count} ç¯‡")
            print(f"  â±ï¸ å“åº”æ—¶é—´: {elapsed_time:.2f}ç§’")
            
            # æ˜¾ç¤ºç¤ºä¾‹æ–‡ç« 
            if articles and len(articles) > 0:
                print(f"  ğŸ“° æ–‡ç« ç¤ºä¾‹:")
                for i, article in enumerate(articles[:3], 1):
                    if isinstance(article, dict):
                        title = article.get('title', article.get('Title', 'No Title'))
                        source = article.get('source', article.get('source_info', {}).get('name', 'Unknown'))
                        if isinstance(source, dict):
                            source = source.get('name', 'Unknown')
                        
                        title = title[:60] + '...' if len(str(title)) > 60 else str(title)
                        print(f"     {i}. {title} - {source}")
            
            total_articles += article_count
            
        except json.JSONDecodeError:
            print(f"  âŒ JSONè§£æé”™è¯¯")
        except urllib.error.HTTPError as e:
            print(f"  âŒ HTTPé”™è¯¯ {e.code}: {e.reason}")
        except Exception as e:
            print(f"  âŒ è·å–å¤±è´¥: {str(e)[:50]}...")
    
    print(f"\nğŸ”¢ JSON APIæ€»ç»“:")
    print(f"   æ€»è®¡è·å–æ–‡ç« : {total_articles} ç¯‡")
    return total_articles

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ“° æ–°é—»æ•°æ®æºåŸºç¡€åˆ†æ")
    print("=" * 60)
    print("ä½¿ç”¨Pythonæ ‡å‡†åº“æµ‹è¯•å„ä¸ªæ–°é—»æº...\n")
    
    results = {}
    
    # æµ‹è¯•RSS feeds
    print("ğŸ”„ æ­£åœ¨æµ‹è¯•RSS Feeds...")
    try:
        results['rss_feeds'] = test_rss_feeds_basic()
    except Exception as e:
        print(f"âŒ RSSæµ‹è¯•å‡ºé”™: {e}")
        results['rss_feeds'] = 0
    
    # æµ‹è¯•ç½‘é¡µå†…å®¹
    print("\nğŸ”„ æ­£åœ¨æµ‹è¯•ç½‘é¡µå†…å®¹...")
    try:
        results['web_pages'] = test_web_pages_basic()
    except Exception as e:
        print(f"âŒ ç½‘é¡µæµ‹è¯•å‡ºé”™: {e}")
        results['web_pages'] = 0
    
    # æµ‹è¯•JSON APIs
    print("\nğŸ”„ æ­£åœ¨æµ‹è¯•JSON APIs...")
    try:
        results['json_apis'] = test_json_apis()
    except Exception as e:
        print(f"âŒ JSON APIæµ‹è¯•å‡ºé”™: {e}")
        results['json_apis'] = 0
    
    # ç”ŸæˆæŠ¥å‘Š
    print("\n" + "=" * 60)
    print("ğŸ“Š æ–°é—»æ•°æ®æºè·å–èƒ½åŠ›æŠ¥å‘Š")
    print("=" * 60)
    
    # è®¡ç®—æ€»æ•°
    total_rss = results.get('rss_feeds', 0)
    total_web = results.get('web_pages', 0)
    total_json = results.get('json_apis', 0)
    
    print(f"\nğŸ“ˆ å„æ•°æ®æºè¡¨ç°:")
    
    # RSS Feedsåˆ†æ
    if total_rss > 0:
        print(f"  ğŸŸ¢ RSS Feeds: {total_rss} ç¯‡ç›¸å…³æ–‡ç« ")
        if total_rss >= 30:
            print(f"     è¯„çº§: â­â­â­â­â­ ä¼˜ç§€ - æ•°æ®é‡ä¸°å¯Œ")
        elif total_rss >= 15:
            print(f"     è¯„çº§: â­â­â­â­ è‰¯å¥½ - æ•°æ®é‡é€‚ä¸­")
        elif total_rss >= 5:
            print(f"     è¯„çº§: â­â­â­ ä¸€èˆ¬ - æ•°æ®é‡åå°‘")
        else:
            print(f"     è¯„çº§: â­â­ è¾ƒå·® - æ•°æ®é‡å¾ˆå°‘")
        print(f"     æ¨è: RSSæ˜¯æœ€ç¨³å®šå¯é çš„æ–°é—»æº")
    else:
        print(f"  ğŸ”´ RSS Feeds: æ— æ³•è·å–æ•°æ®")
        print(f"     å¯èƒ½åŸå› : ç½‘ç»œè¿æ¥é—®é¢˜æˆ–RSSæºæš‚æ—¶ä¸å¯ç”¨")
    
    # ç½‘é¡µå†…å®¹åˆ†æ  
    if total_web > 0:
        print(f"  ğŸŸ¡ ç½‘é¡µå†…å®¹: {total_web} ä¸ªç›¸å…³æåŠ")
        print(f"     è¯„çº§: â­â­â­ å¯ç”¨ - éœ€è¦è§£æå¤„ç†")
        print(f"     æ¨è: å¯ä½œä¸ºRSSçš„è¡¥å……æ•°æ®æº")
    else:
        print(f"  ğŸ”´ ç½‘é¡µå†…å®¹: æ— æ³•è·å–æ•°æ®")
    
    # JSON APIåˆ†æ
    if total_json > 0:
        print(f"  ğŸŸ¢ JSON APIs: {total_json} ç¯‡æ–‡ç« ")
        if total_json >= 50:
            print(f"     è¯„çº§: â­â­â­â­â­ ä¼˜ç§€ - ç»“æ„åŒ–æ•°æ®")
        else:
            print(f"     è¯„çº§: â­â­â­â­ è‰¯å¥½ - ç»“æ„åŒ–æ•°æ®")
        print(f"     æ¨è: æä¾›ç»“æ„åŒ–çš„é«˜è´¨é‡æ•°æ®")
    else:
        print(f"  ğŸ”´ JSON APIs: æ— æ³•è·å–æ•°æ®")
    
    # æ€»ä½“è¯„ä¼°
    total_all = total_rss + (total_web // 10) + total_json  # ç½‘é¡µå†…å®¹æƒé‡é™ä½
    
    print(f"\nğŸ“Š ç»¼åˆè¯„ä¼°:")
    print(f"   é¢„ä¼°å¯è·å–æ–°é—»æ–‡ç« æ€»æ•°: {total_all} ç¯‡/å‘¨")
    
    if total_all >= 50:
        print(f"   ğŸ‰ æ–°é—»æ•°æ®è·å–èƒ½åŠ›: ä¼˜ç§€")
        print(f"   ğŸ’¡ å»ºè®®: å½“å‰é…ç½®è¶³å¤Ÿæ”¯æ’‘é«˜è´¨é‡çš„æƒ…ç»ªåˆ†æ")
    elif total_all >= 25:
        print(f"   âœ… æ–°é—»æ•°æ®è·å–èƒ½åŠ›: è‰¯å¥½") 
        print(f"   ğŸ’¡ å»ºè®®: åŸºæœ¬æ»¡è¶³éœ€æ±‚ï¼Œå¯è€ƒè™‘æ·»åŠ æ›´å¤šæº")
    elif total_all >= 10:
        print(f"   âš ï¸ æ–°é—»æ•°æ®è·å–èƒ½åŠ›: ä¸€èˆ¬")
        print(f"   ğŸ’¡ å»ºè®®: éœ€è¦ä¼˜åŒ–é…ç½®æˆ–æ·»åŠ ä»˜è´¹API")
    else:
        print(f"   ğŸš¨ æ–°é—»æ•°æ®è·å–èƒ½åŠ›: ä¸è¶³")
        print(f"   ğŸ’¡ å»ºè®®: æ£€æŸ¥ç½‘ç»œè¿æ¥ï¼Œè€ƒè™‘ä½¿ç”¨ä»˜è´¹API")
    
    # å®æ–½å»ºè®®
    print(f"\nğŸ› ï¸ å®æ–½å»ºè®®:")
    if total_rss > 0:
        print(f"   1. âœ… RSS Feeds ä¼˜å…ˆ - ç¨³å®šå¯é çš„ä¸»è¦æ•°æ®æº")
    if total_json > 0:
        print(f"   2. âœ… JSON APIs è¡¥å…… - ç»“æ„åŒ–æ•°æ®è´¨é‡é«˜") 
    
    print(f"   3. ğŸ“¦ å¤šæºèšåˆç­–ç•¥:")
    print(f"      â€¢ RSS Feeds ä½œä¸ºä¸»è¦æ•°æ®æº (70%æƒé‡)")
    print(f"      â€¢ JSON APIs ä½œä¸ºè¡¥å……æ•°æ®æº (20%æƒé‡)") 
    print(f"      â€¢ ç½‘é¡µæŠ“å–ä½œä¸ºå¤‡ç”¨æ•°æ®æº (10%æƒé‡)")
    
    print(f"   4. ğŸ¯ ä¼˜åŒ–æ–¹å‘:")
    if total_rss < 20:
        print(f"      â€¢ æ·»åŠ æ›´å¤šRSSæºæé«˜è¦†ç›–é¢")
    if total_json == 0:
        print(f"      â€¢ é›†æˆå…è´¹çš„JSON API (CoinGecko, CryptoCompare)")
    print(f"      â€¢ å®ç°æ™ºèƒ½ç¼“å­˜å‡å°‘é‡å¤è¯·æ±‚")
    print(f"      â€¢ æ·»åŠ æƒ…ç»ªåˆ†æå’Œå…³é”®è¯è¿‡æ»¤")
    
    return results

if __name__ == "__main__":
    main()