#!/usr/bin/env python3
"""
ä½¿ç”¨Pythonæ ‡å‡†åº“æµ‹è¯•ç¤¾äº¤åª’ä½“æ•°æ®æºè·å–èƒ½åŠ›
åŒ…æ‹¬Twitterã€YouTubeã€Telegramçš„æ•°æ®è·å–åˆ†æ
"""
import urllib.request
import urllib.parse
import json
import re
import time
from datetime import datetime, timedelta

def test_twitter_alternatives():
    """æµ‹è¯•Twitteræ›¿ä»£æ•°æ®æº"""
    print("=== Twitter æ›¿ä»£æ•°æ®æºæµ‹è¯• ===")
    
    # æµ‹è¯•ä¸€äº›å¯ä»¥è·å–Twitterç›¸å…³ä¿¡æ¯çš„å…¬å¼€API
    sources = [
        ("Twitterå…¬å¼€æœç´¢", "https://twitter.com/search", "BTC"),
        ("Nitterå®ä¾‹", "https://nitter.net/search", "Bitcoin")
    ]
    
    total_data = 0
    
    for name, base_url, query in sources:
        print(f"\nğŸ¦ æµ‹è¯• {name}")
        try:
            if "twitter.com" in base_url:
                # Twitterçš„å…¬å¼€æœç´¢é¡µé¢
                search_url = f"{base_url}?q={urllib.parse.quote(query)}&src=typed_query&f=live"
            else:
                # Nitteræœç´¢
                search_url = f"{base_url}?q={urllib.parse.quote(query)}"
            
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
                'Accept-Language': 'en-US,en;q=0.5',
                'Connection': 'keep-alive'
            }
            
            request = urllib.request.Request(search_url, headers=headers)
            
            start_time = time.time()
            try:
                with urllib.request.urlopen(request, timeout=15) as response:
                    content = response.read().decode('utf-8', errors='ignore')
                elapsed_time = time.time() - start_time
                
                # åˆ†æé¡µé¢å†…å®¹å¯»æ‰¾æ¨æ–‡ç›¸å…³ä¿¡æ¯
                if "twitter.com" in base_url:
                    # Twitteré¡µé¢åˆ†æ
                    tweet_patterns = [
                        r'"tweet_count":\s*(\d+)',
                        r'data-testid="tweet"',
                        r'role="article"'
                    ]
                    
                    tweet_indicators = 0
                    for pattern in tweet_patterns:
                        matches = re.findall(pattern, content, re.IGNORECASE)
                        tweet_indicators += len(matches)
                    
                    # æ£€æŸ¥æ˜¯å¦åŒ…å«æ¨æ–‡å†…å®¹
                    btc_mentions = len(re.findall(r'\b(btc|bitcoin|crypto)\b', content, re.IGNORECASE))
                    
                else:
                    # Nitteré¡µé¢åˆ†æ
                    tweet_containers = re.findall(r'class="tweet-content"', content, re.IGNORECASE)
                    btc_mentions = len(re.findall(r'\b(btc|bitcoin|crypto)\b', content, re.IGNORECASE))
                    tweet_indicators = len(tweet_containers)
                
                print(f"  âœ… é¡µé¢åŠ è½½æˆåŠŸ")
                print(f"  ğŸ“„ é¡µé¢å¤§å°: {len(content):,} å­—ç¬¦")
                print(f"  ğŸ” æ¨æ–‡æŒ‡æ ‡: {tweet_indicators} ä¸ª")
                print(f"  ğŸ¯ ç›¸å…³å†…å®¹: {btc_mentions} ä¸ªæåŠ")
                print(f"  â±ï¸ å“åº”æ—¶é—´: {elapsed_time:.2f}ç§’")
                
                if tweet_indicators > 0:
                    print(f"  ğŸ“Š è¯„ä¼°: å¯è·å–çº¦ {tweet_indicators} æ¡æ¨æ–‡æ•°æ®")
                else:
                    print(f"  âš ï¸ è¯„ä¼°: å¯èƒ½è¢«é™åˆ¶è®¿é—®æˆ–éœ€è¦è®¤è¯")
                
                total_data += min(tweet_indicators, btc_mentions)
                
            except urllib.error.HTTPError as e:
                if e.code == 429:
                    print(f"  ğŸš« è®¿é—®è¢«é™åˆ¶ (429 Too Many Requests)")
                    print(f"  ğŸ’¡ è¯´æ˜: Twitteré™åˆ¶åŒ¿åè®¿é—®ï¼Œéœ€è¦APIå¯†é’¥")
                elif e.code == 403:
                    print(f"  ğŸš« è®¿é—®è¢«ç¦æ­¢ (403 Forbidden)")
                    print(f"  ğŸ’¡ è¯´æ˜: éœ€è¦ç™»å½•æˆ–APIè®¤è¯")
                else:
                    print(f"  âŒ HTTPé”™è¯¯ {e.code}: {e.reason}")
                    
        except Exception as e:
            print(f"  âŒ è·å–å¤±è´¥: {str(e)[:60]}...")
    
    print(f"\nğŸ”¢ Twitteræ•°æ®æºæ€»ç»“:")
    print(f"   é¢„ä¼°å¯è·å–æ•°æ®é‡: {total_data} æ¡")
    
    # å…è´¹æ›¿ä»£æ–¹æ¡ˆåˆ†æ
    print(f"\nğŸ’¡ Twitterå…è´¹æ›¿ä»£æ–¹æ¡ˆåˆ†æ:")
    print(f"   ğŸ”“ Nitterå®ä¾‹: å…è´¹ä½†å¯èƒ½ä¸ç¨³å®š")
    print(f"   ğŸ”“ Twikit: éœ€è¦å®‰è£…ï¼Œå¯ç»•è¿‡éƒ¨åˆ†é™åˆ¶")
    print(f"   ğŸ”“ snscrape: å‘½ä»¤è¡Œå·¥å…·ï¼ŒåŠŸèƒ½å¼ºå¤§")
    print(f"   ğŸ’° å®˜æ–¹API: $200/æœˆèµ·ï¼Œæ•°æ®è´¨é‡æœ€é«˜")
    
    return total_data

def test_youtube_sources():
    """æµ‹è¯•YouTubeæ•°æ®æº"""
    print("\n=== YouTube æ•°æ®æºæµ‹è¯• ===")
    
    # æµ‹è¯•YouTubeç›¸å…³çš„æ•°æ®è·å–
    test_scenarios = [
        ("YouTubeæœç´¢é¡µé¢", "https://www.youtube.com/results", "Bitcoin"),
        ("åŠ å¯†è´§å¸é¢‘é“", "https://www.youtube.com/c/CoinBureau", None)
    ]
    
    total_videos = 0
    
    for name, base_url, query in test_scenarios:
        print(f"\nğŸ“º æµ‹è¯• {name}")
        try:
            if query:
                search_url = f"{base_url}?search_query={urllib.parse.quote(query)}"
            else:
                search_url = base_url
            
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8'
            }
            
            request = urllib.request.Request(search_url, headers=headers)
            
            start_time = time.time()
            with urllib.request.urlopen(request, timeout=20) as response:
                content = response.read().decode('utf-8', errors='ignore')
            elapsed_time = time.time() - start_time
            
            # åˆ†æYouTubeé¡µé¢å†…å®¹
            video_patterns = [
                r'"videoId":"([^"]+)"',
                r'watch\?v=([a-zA-Z0-9_-]{11})',
                r'"title":{"runs":\[{"text":"([^"]+)"}\]',
                r'"videoRenderer"'
            ]
            
            video_ids = set()
            video_titles = []
            
            for pattern in video_patterns[:2]:  # è§†é¢‘IDæ¨¡å¼
                matches = re.findall(pattern, content)
                if matches:
                    video_ids.update(matches)
            
            # æå–è§†é¢‘æ ‡é¢˜
            title_pattern = r'"title":{"runs":\[{"text":"([^"]+)"}\]'
            titles = re.findall(title_pattern, content)
            for title in titles:
                if any(keyword in title.lower() for keyword in ['bitcoin', 'btc', 'crypto', 'blockchain']):
                    video_titles.append(title)
            
            # æ£€æŸ¥åŠ å¯†è´§å¸ç›¸å…³å†…å®¹
            crypto_mentions = len(re.findall(r'\b(bitcoin|btc|crypto|ethereum|eth|blockchain)\b', content, re.IGNORECASE))
            
            print(f"  âœ… é¡µé¢åŠ è½½æˆåŠŸ")
            print(f"  ğŸ“„ é¡µé¢å¤§å°: {len(content):,} å­—ç¬¦")
            print(f"  ğŸ¬ å‘ç°è§†é¢‘ID: {len(video_ids)} ä¸ª")
            print(f"  ğŸ“ ç›¸å…³è§†é¢‘æ ‡é¢˜: {len(video_titles)} ä¸ª")
            print(f"  ğŸ” åŠ å¯†è´§å¸æåŠ: {crypto_mentions} æ¬¡")
            print(f"  â±ï¸ å“åº”æ—¶é—´: {elapsed_time:.2f}ç§’")
            
            # æ˜¾ç¤ºç›¸å…³è§†é¢‘ç¤ºä¾‹
            if video_titles:
                print(f"  ğŸ“º è§†é¢‘æ ‡é¢˜ç¤ºä¾‹:")
                for i, title in enumerate(video_titles[:3], 1):
                    title = title[:60] + '...' if len(title) > 60 else title
                    print(f"     {i}. {title}")
            
            total_videos += len(video_ids)
            
        except urllib.error.HTTPError as e:
            print(f"  âŒ HTTPé”™è¯¯ {e.code}: {e.reason}")
        except Exception as e:
            print(f"  âŒ è·å–å¤±è´¥: {str(e)[:60]}...")
    
    print(f"\nğŸ”¢ YouTubeæ•°æ®æºæ€»ç»“:")
    print(f"   é¢„ä¼°å¯è·å–è§†é¢‘æ•°: {total_videos} ä¸ª")
    
    # YouTube APIåˆ†æ
    print(f"\nğŸ’¡ YouTubeæ•°æ®è·å–æ–¹æ¡ˆ:")
    print(f"   ğŸ†“ YouTube Data API v3: å…è´¹é…é¢10,000å•ä½/å¤©")
    print(f"   ğŸ”“ yt-dlp: å…è´¹å·¥å…·ï¼ŒåŠŸèƒ½å¼ºå¤§")
    print(f"   ğŸ” ç½‘é¡µæŠ“å–: å¤æ‚ä½†å¯è¡Œ")
    print(f"   ğŸ“Š è¯„ä¼°: å…è´¹æ–¹æ¡ˆè¶³å¤Ÿè·å–å½±å“è€…è§‚ç‚¹")
    
    return total_videos

def test_telegram_sources():
    """æµ‹è¯•Telegramæ•°æ®æº"""
    print("\n=== Telegram æ•°æ®æºæµ‹è¯• ===")
    
    # Telegramå…¬å¼€é¢‘é“æµ‹è¯•
    public_channels = [
        ("Telegram Webæœç´¢", "https://t.me/s/", "bitcoin"),
        ("å…¬å¼€é¢‘é“ç¤ºä¾‹", "https://t.me/s/CryptoNews", None)
    ]
    
    total_messages = 0
    
    for name, base_url, channel in public_channels:
        print(f"\nğŸ“± æµ‹è¯• {name}")
        try:
            if channel and not channel.startswith('http'):
                test_url = f"{base_url}{channel}"
            elif channel:
                test_url = channel
            else:
                test_url = base_url
            
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
            }
            
            request = urllib.request.Request(test_url, headers=headers)
            
            start_time = time.time()
            with urllib.request.urlopen(request, timeout=15) as response:
                content = response.read().decode('utf-8', errors='ignore')
            elapsed_time = time.time() - start_time
            
            # åˆ†æTelegramé¡µé¢å†…å®¹
            message_patterns = [
                r'class="tgme_widget_message_text"',
                r'data-post="[^"]+/(\d+)"',
                r'tgme_widget_message_bubble'
            ]
            
            message_indicators = 0
            for pattern in message_patterns:
                matches = re.findall(pattern, content, re.IGNORECASE)
                message_indicators += len(matches)
            
            # æ£€æŸ¥åŠ å¯†è´§å¸ç›¸å…³å†…å®¹
            crypto_mentions = len(re.findall(r'\b(bitcoin|btc|crypto|ethereum|blockchain)\b', content, re.IGNORECASE))
            
            # å¯»æ‰¾æ¶ˆæ¯æ–‡æœ¬
            message_texts = re.findall(r'class="tgme_widget_message_text[^"]*">([^<]+)', content, re.IGNORECASE)
            relevant_messages = [msg for msg in message_texts if any(keyword in msg.lower() for keyword in ['bitcoin', 'btc', 'crypto'])]
            
            print(f"  âœ… é¡µé¢åŠ è½½æˆåŠŸ")
            print(f"  ğŸ“„ é¡µé¢å¤§å°: {len(content):,} å­—ç¬¦")
            print(f"  ğŸ’¬ æ¶ˆæ¯æŒ‡æ ‡: {message_indicators} ä¸ª")
            print(f"  ğŸ“ æå–æ¶ˆæ¯: {len(message_texts)} æ¡")
            print(f"  ğŸ¯ ç›¸å…³æ¶ˆæ¯: {len(relevant_messages)} æ¡")
            print(f"  ğŸ” åŠ å¯†è´§å¸æåŠ: {crypto_mentions} æ¬¡")
            print(f"  â±ï¸ å“åº”æ—¶é—´: {elapsed_time:.2f}ç§’")
            
            # æ˜¾ç¤ºç›¸å…³æ¶ˆæ¯ç¤ºä¾‹
            if relevant_messages:
                print(f"  ğŸ“¨ ç›¸å…³æ¶ˆæ¯ç¤ºä¾‹:")
                for i, msg in enumerate(relevant_messages[:2], 1):
                    msg = msg[:80] + '...' if len(msg) > 80 else msg
                    print(f"     {i}. {msg}")
            
            total_messages += max(message_indicators // 3, len(relevant_messages))
            
        except urllib.error.HTTPError as e:
            print(f"  âŒ HTTPé”™è¯¯ {e.code}: {e.reason}")
            if e.code == 404:
                print(f"  ğŸ’¡ é¢‘é“å¯èƒ½ä¸å­˜åœ¨æˆ–å·²è®¾ä¸ºç§äººé¢‘é“")
        except Exception as e:
            print(f"  âŒ è·å–å¤±è´¥: {str(e)[:60]}...")
    
    print(f"\nğŸ”¢ Telegramæ•°æ®æºæ€»ç»“:")
    print(f"   é¢„ä¼°å¯è·å–æ¶ˆæ¯æ•°: {total_messages} æ¡")
    
    # Telegram APIåˆ†æ
    print(f"\nğŸ’¡ Telegramæ•°æ®è·å–æ–¹æ¡ˆ:")
    print(f"   ğŸ†“ Telegram Bot API: å…è´¹ä½†åŠŸèƒ½æœ‰é™")
    print(f"   ğŸ”‘ Telegram Client API: éœ€è¦ç”³è¯·ä½†å…è´¹")
    print(f"   ğŸ”“ Pyrogram/Telethon: å¼ºå¤§çš„Pythonå®¢æˆ·ç«¯")
    print(f"   ğŸŒ å…¬å¼€é¢‘é“ç½‘é¡µ: å¯ä»¥æŠ“å–éƒ¨åˆ†æ•°æ®")
    print(f"   ğŸ“Š è¯„ä¼°: å…è´¹æ–¹æ¡ˆå¯è·å–å…¬å¼€é¢‘é“æ•°æ®")
    
    return total_messages

def test_social_apis():
    """æµ‹è¯•ç¤¾äº¤åª’ä½“ç›¸å…³çš„API"""
    print("\n=== ç¤¾äº¤åª’ä½“ API æµ‹è¯• ===")
    
    apis = [
        ("Reddit JSON", "https://www.reddit.com/r/cryptocurrency/hot.json"),
        ("HackerNews API", "https://hacker-news.firebaseio.com/v0/topstories.json")
    ]
    
    total_posts = 0
    
    for name, url in apis:
        print(f"\nğŸ”— æµ‹è¯• {name}")
        try:
            headers = {
                'User-Agent': 'Python Social Media Analysis Bot 1.0'
            }
            
            request = urllib.request.Request(url, headers=headers)
            
            start_time = time.time()
            with urllib.request.urlopen(request, timeout=15) as response:
                content = response.read().decode('utf-8')
            elapsed_time = time.time() - start_time
            
            data = json.loads(content)
            
            posts_count = 0
            relevant_posts = 0
            
            if 'reddit.com' in url:
                # Reddit JSONæ ¼å¼
                if isinstance(data, dict) and 'data' in data:
                    posts = data['data'].get('children', [])
                    posts_count = len(posts)
                    
                    for post in posts:
                        if isinstance(post, dict) and 'data' in post:
                            title = post['data'].get('title', '').lower()
                            if any(keyword in title for keyword in ['bitcoin', 'btc', 'crypto']):
                                relevant_posts += 1
            else:
                # HackerNews API
                if isinstance(data, list):
                    posts_count = len(data)
                    # HNè¿”å›IDåˆ—è¡¨ï¼Œè¿™é‡Œç®€åŒ–å¤„ç†
                    relevant_posts = posts_count // 10  # ä¼°ç®—ç›¸å…³å¸–å­
            
            print(f"  âœ… APIå“åº”æˆåŠŸ")
            print(f"  ğŸ“Š è·å–å¸–å­: {posts_count} ä¸ª")
            print(f"  ğŸ¯ ç›¸å…³å†…å®¹: {relevant_posts} ä¸ª")
            print(f"  â±ï¸ å“åº”æ—¶é—´: {elapsed_time:.2f}ç§’")
            
            total_posts += relevant_posts
            
        except json.JSONDecodeError:
            print(f"  âŒ JSONè§£æé”™è¯¯")
        except Exception as e:
            print(f"  âŒ è·å–å¤±è´¥: {str(e)[:50]}...")
    
    print(f"\nğŸ”¢ ç¤¾äº¤åª’ä½“APIæ€»ç»“:")
    print(f"   æ€»è®¡ç›¸å…³å¸–å­: {total_posts} ä¸ª")
    return total_posts

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ“± ç¤¾äº¤åª’ä½“æ•°æ®æºè·å–èƒ½åŠ›åˆ†æ")
    print("=" * 60)
    print("æµ‹è¯•Twitterã€YouTubeã€Telegramæ•°æ®è·å–èƒ½åŠ›...\n")
    
    results = {}
    
    # æµ‹è¯•Twitter
    print("ğŸ”„ æ­£åœ¨æµ‹è¯•Twitteræ•°æ®æº...")
    try:
        results['twitter'] = test_twitter_alternatives()
    except Exception as e:
        print(f"âŒ Twitteræµ‹è¯•å‡ºé”™: {e}")
        results['twitter'] = 0
    
    # æµ‹è¯•YouTube
    print("\nğŸ”„ æ­£åœ¨æµ‹è¯•YouTubeæ•°æ®æº...")
    try:
        results['youtube'] = test_youtube_sources()
    except Exception as e:
        print(f"âŒ YouTubeæµ‹è¯•å‡ºé”™: {e}")
        results['youtube'] = 0
    
    # æµ‹è¯•Telegram
    print("\nğŸ”„ æ­£åœ¨æµ‹è¯•Telegramæ•°æ®æº...")
    try:
        results['telegram'] = test_telegram_sources()
    except Exception as e:
        print(f"âŒ Telegramæµ‹è¯•å‡ºé”™: {e}")
        results['telegram'] = 0
    
    # æµ‹è¯•å…¶ä»–ç¤¾äº¤API
    print("\nğŸ”„ æ­£åœ¨æµ‹è¯•å…¶ä»–ç¤¾äº¤åª’ä½“API...")
    try:
        results['social_apis'] = test_social_apis()
    except Exception as e:
        print(f"âŒ ç¤¾äº¤APIæµ‹è¯•å‡ºé”™: {e}")
        results['social_apis'] = 0
    
    # ç”Ÿæˆç»¼åˆæŠ¥å‘Š
    print("\n" + "=" * 60)
    print("ğŸ“Š ç¤¾äº¤åª’ä½“æ•°æ®æºè·å–èƒ½åŠ›æŠ¥å‘Š")
    print("=" * 60)
    
    total_twitter = results.get('twitter', 0)
    total_youtube = results.get('youtube', 0)
    total_telegram = results.get('telegram', 0)
    total_social = results.get('social_apis', 0)
    
    print(f"\nğŸ“ˆ å„å¹³å°æ•°æ®è·å–èƒ½åŠ›:")
    
    # Twitteråˆ†æ
    print(f"\nğŸ¦ Twitter:")
    if total_twitter > 0:
        print(f"   ğŸ“Š é¢„ä¼°æ•°æ®é‡: {total_twitter} æ¡æ¨æ–‡")
        print(f"   ğŸ“ˆ è·å–éš¾åº¦: ğŸ”´ å›°éš¾ (éœ€è¦APIå¯†é’¥æˆ–ç‰¹æ®Šå·¥å…·)")
        print(f"   ğŸ’° æˆæœ¬è¯„ä¼°: $200+/æœˆ (å®˜æ–¹API)")
        print(f"   ğŸ”“ å…è´¹æ–¹æ¡ˆ: Twikit, snscrape (ä¸ç¨³å®š)")
        print(f"   â­ æ¨èæŒ‡æ•°: â­â­ (é«˜æˆæœ¬)")
    else:
        print(f"   ğŸ“Š é¢„ä¼°æ•°æ®é‡: 0 æ¡ (è®¿é—®å—é™)")
        print(f"   ğŸ“ˆ è·å–éš¾åº¦: ğŸ”´ å¾ˆå›°éš¾ (ä¸¥æ ¼é™åˆ¶)")
        print(f"   ğŸ’¡ è§£å†³æ–¹æ¡ˆ: ä½¿ç”¨å…è´¹æ›¿ä»£å·¥å…· (Twikit)")
        print(f"   â­ æ¨èæŒ‡æ•°: â­â­â­ (æœ‰å…è´¹æ›¿ä»£æ–¹æ¡ˆ)")
    
    # YouTubeåˆ†æ
    print(f"\nğŸ“º YouTube:")
    if total_youtube > 0:
        print(f"   ğŸ“Š é¢„ä¼°æ•°æ®é‡: {total_youtube} ä¸ªè§†é¢‘")
        print(f"   ğŸ“ˆ è·å–éš¾åº¦: ğŸŸ¡ ä¸­ç­‰ (éœ€è¦è§£ææˆ–API)")
        print(f"   ğŸ’° æˆæœ¬è¯„ä¼°: å…è´¹é…é¢å……è¶³")
        print(f"   ğŸ”“ å…è´¹æ–¹æ¡ˆ: YouTube Data API v3, yt-dlp")
        print(f"   â­ æ¨èæŒ‡æ•°: â­â­â­â­ (å…è´¹ä¸”ç¨³å®š)")
    else:
        print(f"   ğŸ“Š é¢„ä¼°æ•°æ®é‡: 0 ä¸ª (è·å–å¤±è´¥)")
        print(f"   ğŸ’¡ è§£å†³æ–¹æ¡ˆ: é…ç½®YouTube Data APIå¯†é’¥")
        print(f"   â­ æ¨èæŒ‡æ•°: â­â­â­â­ (é…ç½®åæ•ˆæœå¥½)")
    
    # Telegramåˆ†æ
    print(f"\nğŸ“± Telegram:")
    if total_telegram > 0:
        print(f"   ğŸ“Š é¢„ä¼°æ•°æ®é‡: {total_telegram} æ¡æ¶ˆæ¯")
        print(f"   ğŸ“ˆ è·å–éš¾åº¦: ğŸŸ¡ ä¸­ç­‰ (éœ€è¦APIç”³è¯·)")
        print(f"   ğŸ’° æˆæœ¬è¯„ä¼°: å…è´¹ä½†éœ€è¦ç”³è¯·")
        print(f"   ğŸ”“ å…è´¹æ–¹æ¡ˆ: Pyrogram, Telethon")
        print(f"   â­ æ¨èæŒ‡æ•°: â­â­â­â­ (å…è´¹ä¸”æ•°æ®è´¨é‡å¥½)")
    else:
        print(f"   ğŸ“Š é¢„ä¼°æ•°æ®é‡: 0 æ¡ (è®¿é—®å—é™)")
        print(f"   ğŸ’¡ è§£å†³æ–¹æ¡ˆ: ç”³è¯·Telegram APIæˆ–ä½¿ç”¨å…¬å¼€é¢‘é“")
        print(f"   â­ æ¨èæŒ‡æ•°: â­â­â­ (é…ç½®åå¯ç”¨)")
    
    # å…¶ä»–ç¤¾äº¤åª’ä½“
    if total_social > 0:
        print(f"\nğŸŒ å…¶ä»–ç¤¾äº¤åª’ä½“:")
        print(f"   ğŸ“Š æ•°æ®é‡: {total_social} ä¸ªå¸–å­")
        print(f"   ğŸ’¡ åŒ…å«: Redditç­‰å…è´¹API")
        print(f"   â­ æ¨èæŒ‡æ•°: â­â­â­â­ (è¡¥å……æ•°æ®æº)")
    
    # ç»¼åˆè¯„ä¼°
    total_all = total_youtube + total_telegram + total_social + (total_twitter // 10)
    
    print(f"\nğŸ“Š ç»¼åˆç¤¾äº¤åª’ä½“æ•°æ®è·å–èƒ½åŠ›:")
    print(f"   ğŸ¯ é¢„ä¼°æ€»æ•°æ®é‡: {total_all} æ¡/å‘¨")
    
    if total_all >= 100:
        print(f"   ğŸ‰ æ•°æ®è·å–èƒ½åŠ›: ä¼˜ç§€")
        print(f"   ğŸ’¡ å»ºè®®: å½“å‰é…ç½®è¶³å¤Ÿæ”¯æ’‘æƒ…ç»ªåˆ†æ")
    elif total_all >= 50:
        print(f"   âœ… æ•°æ®è·å–èƒ½åŠ›: è‰¯å¥½")
        print(f"   ğŸ’¡ å»ºè®®: å¯ä»¥æ»¡è¶³åŸºæœ¬éœ€æ±‚")
    elif total_all >= 20:
        print(f"   âš ï¸ æ•°æ®è·å–èƒ½åŠ›: ä¸€èˆ¬")
        print(f"   ğŸ’¡ å»ºè®®: éœ€è¦é…ç½®APIæˆ–ä½¿ç”¨æ›¿ä»£å·¥å…·")
    else:
        print(f"   ğŸš¨ æ•°æ®è·å–èƒ½åŠ›: ä¸è¶³")
        print(f"   ğŸ’¡ å»ºè®®: é‡ç‚¹é…ç½®å…è´¹APIå’Œæ›¿ä»£å·¥å…·")
    
    # å®æ–½å»ºè®®
    print(f"\nğŸ› ï¸ å®æ–½å»ºè®®:")
    print(f"   1. ğŸ¯ ä¼˜å…ˆçº§æ’åº:")
    print(f"      â€¢ YouTube Data API > Telegram API > Twitteræ›¿ä»£å·¥å…·")
    print(f"   2. ğŸ“‹ é…ç½®æ­¥éª¤:")
    print(f"      â€¢ ç”³è¯·YouTube Data API v3 (å…è´¹)")
    print(f"      â€¢ ç”³è¯·Telegram API credentials (å…è´¹)")
    print(f"      â€¢ å®‰è£…Twikit/snscrapeä½œä¸ºTwitteræ›¿ä»£")
    print(f"   3. ğŸ’° æˆæœ¬æ§åˆ¶:")
    print(f"      â€¢ å…¨éƒ¨ä½¿ç”¨å…è´¹æ–¹æ¡ˆ: $0/æœˆ")
    print(f"      â€¢ YouTube + Telegram + Twitteræ›¿ä»£å·¥å…·")
    print(f"   4. ğŸ”„ å®¹é”™ç­–ç•¥:")
    print(f"      â€¢ å¤šä¸ªæ›¿ä»£å·¥å…·å¤‡ä»½")
    print(f"      â€¢ æ™ºèƒ½é™çº§åˆ°æ¨¡æ‹Ÿæ•°æ®")
    
    print(f"\nğŸ¯ ç»“è®º:")
    if total_youtube > 0 or total_telegram > 0:
        print(f"   âœ… ç¤¾äº¤åª’ä½“æ•°æ®è·å–åŸºç¡€è‰¯å¥½")
        print(f"   ğŸ”§ é€šè¿‡é…ç½®APIå¯å¤§å¹…æå‡æ•°æ®é‡")
        print(f"   ğŸ’¡ é‡ç‚¹å…³æ³¨YouTubeå’ŒTelegramçš„APIé…ç½®")
    else:
        print(f"   âš ï¸ éœ€è¦é…ç½®APIå¯†é’¥æ‰èƒ½å‘æŒ¥å…¨éƒ¨æ½œåŠ›")
        print(f"   ğŸ†“ ä¼˜å…ˆä½¿ç”¨å…è´¹çš„APIå’Œå·¥å…·")
        print(f"   ğŸ“ˆ é…ç½®åé¢„ä¼°å¯è·å–æ•°æ®é‡: 200+ æ¡/å‘¨")
    
    return results

if __name__ == "__main__":
    main()