---
name: API速率限制和故障转移机制
type: task
epic: 数据收集代理
status: open
priority: 2
created: 2025-09-25T20:20:35Z
estimated: 6 days
assigned: [待分配]
parallelizable: true
dependencies: ["004"]
---

# 任务: API速率限制和故障转移机制

## 任务描述
实现智能API速率限制和故障转移机制，包含精确的速率限制算法、实时故障检测、自动恢复策略和熔断机制，确保系统在高负载和异常情况下的稳定性和可靠性。

## 技术要求

### 核心架构设计

#### 速率限制管理器
- **分布式限制**: 基于Redis的分布式速率限制
- **多维度限制**: 支持交易所、端点、IP等多维度限制
- **滑动窗口**: 高精度的滑动窗口算法
- **动态调整**: 根据响应时间动态调整限制

#### 故障转移管理器
- **故障检测**: 多层次的故障检测机制
- **自动转移**: 智能的负载重分配
- **健康检查**: 实时连接状态监控
- **恢复机制**: 渐进式恢复策略

#### 熔断机制
- **熔断模式**: 支持熔断、半开、关闭状态
- **错误率监控**: 实时错误率统计
- **自动恢复**: 基于成功率的自动恢复
- **降级策略**: 优雅的服务降级

### 实现架构

```python
# src/core/rate_limiter.py
import asyncio
import time
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass, asdict
from enum import Enum
import json
import redis.asyncio as redis
from collections import defaultdict, deque
import statistics
from ..core.config import config
from ..core.logger import get_logger
from ..core.metrics import metrics
from ..core.exceptions import RateLimitError, CircuitBreakerError

class RateLimitAlgorithm(Enum):
    """速率限制算法枚举"""
    FIXED_WINDOW = "fixed_window"
    SLIDING_WINDOW = "sliding_window"
    TOKEN_BUCKET = "token_bucket"
    LEAKY_BUCKET = "leaky_bucket"

class CircuitState(Enum):
    """熔断器状态枚举"""
    CLOSED = "closed"      # 关闭状态，正常请求
    OPEN = "open"         # 开启状态，拒绝请求
    HALF_OPEN = "half_open"  # 半开状态，允许部分请求

@dataclass
class RateLimitConfig:
    """速率限制配置"""
    limit: int
    window: int  # 时间窗口（秒）
    algorithm: RateLimitAlgorithm = RateLimitAlgorithm.SLIDING_WINDOW
    burst_limit: Optional[int] = None  # 突发限制

@dataclass
class CircuitBreakerConfig:
    """熔断器配置"""
    failure_threshold: int = 5          # 失败阈值
    recovery_threshold: int = 3         # 恢复阈值
    timeout: int = 60                  # 超时时间（秒）
    expected_exception: Tuple = (Exception,)  # 预期异常类型
    call_timeout: int = 30             # 调用超时时间

class AdvancedRateLimiter:
    """高级速率限制器"""

    def __init__(self, redis_client: redis.Redis = None):
        self.redis_client = redis_client
        self.logger = get_logger("advanced_rate_limiter")
        self.configs: Dict[str, RateLimitConfig] = {}
        self.local_counters = defaultdict(lambda: defaultdict(int))
        self.last_cleanup = time.time()
        self.cleanup_interval = 300  # 5分钟清理一次

    async def initialize(self):
        """初始化速率限制器"""
        # 加载配置
        rate_limit_config = config.get('rate_limit', {})

        for key, cfg in rate_limit_config.items():
            self.configs[key] = RateLimitConfig(**cfg)

        self.logger.info(f"速率限制器初始化完成，加载 {len(self.configs)} 个配置")

    async def acquire_permit(self, key: str, weight: int = 1) -> bool:
        """获取请求许可"""
        if key not in self.configs:
            self.logger.warning(f"未找到速率限制配置: {key}")
            return True

        config = self.configs[key]

        if self.redis_client:
            return await self._acquire_redis_permit(key, config, weight)
        else:
            return await self._acquire_local_permit(key, config, weight)

    async def _acquire_redis_permit(self, key: str, config: RateLimitConfig, weight: int) -> bool:
        """基于Redis的分布式速率限制"""
        try:
            if config.algorithm == RateLimitAlgorithm.SLIDING_WINDOW:
                return await self._sliding_window_redis(key, config, weight)
            elif config.algorithm == RateLimitAlgorithm.TOKEN_BUCKET:
                return await self._token_bucket_redis(key, config, weight)
            elif config.algorithm == RateLimitAlgorithm.FIXED_WINDOW:
                return await self._fixed_window_redis(key, config, weight)
            else:
                return await self._leaky_bucket_redis(key, config, weight)

        except Exception as e:
            self.logger.error(f"Redis速率限制失败: {e}")
            # 降级到本地限制
            return await self._acquire_local_permit(key, config, weight)

    async def _sliding_window_redis(self, key: str, config: RateLimitConfig, weight: int) -> bool:
        """Redis滑动窗口算法"""
        current_time = time.time()
        window_start = current_time - config.window

        # 使用Redis的有序集合实现滑动窗口
        pipe = self.redis_client.pipeline()

        # 移除窗口外的请求
        pipe.zremrangebyscore(f"rate_limit:{key}", 0, window_start)

        # 获取当前窗口内的请求数
        pipe.zcard(f"rate_limit:{key}")

        # 如果还有余量，添加当前请求
        current_count = await pipe.execute()[-1]

        if current_count + weight <= config.limit:
            # 添加当前请求
            await self.redis_client.zadd(f"rate_limit:{key}", {str(current_time): current_time})
            await self.redis_client.expire(f"rate_limit:{key}", config.window)
            return True
        else:
            return False

    async def _token_bucket_redis(self, key: str, config: RateLimitConfig, weight: int) -> bool:
        """Redis令牌桶算法"""
        current_time = time.time()

        pipe = self.redis_client.pipeline()

        # 获取当前令牌数和时间戳
        pipe.hget(f"token_bucket:{key}", "tokens")
        pipe.hget(f"token_bucket:{key}", "last_refill")

        results = await pipe.execute()

        tokens = float(results[0] or config.limit)
        last_refill = float(results[1] or current_time)

        # 计算时间差和补充的令牌
        time_diff = current_time - last_refill
        refill_rate = config.limit / config.window
        new_tokens = min(config.limit, tokens + time_diff * refill_rate)

        if new_tokens >= weight:
            # 消费令牌
            remaining_tokens = new_tokens - weight

            # 更新令牌桶
            await self.redis_client.hset(f"token_bucket:{key}", mapping={
                "tokens": remaining_tokens,
                "last_refill": current_time
            })
            await self.redis_client.expire(f"token_bucket:{key}", config.window)

            return True
        else:
            return False

    async def _fixed_window_redis(self, key: str, config: RateLimitConfig, weight: int) -> bool:
        """Redis固定窗口算法"""
        current_time = time.time()
        window = int(current_time // config.window)

        window_key = f"fixed_window:{key}:{window}"

        # 使用原子操作递增计数器
        current_count = await self.redis_client.incrby(window_key, weight)

        if current_count == weight:  # 第一次设置过期时间
            await self.redis_client.expire(window_key, config.window * 2)

        return current_count <= config.limit

    async def _leaky_bucket_redis(self, key: str, config: RateLimitConfig, weight: int) -> bool:
        """Redis漏桶算法"""
        current_time = time.time()

        pipe = self.redis_client.pipeline()

        # 获取桶中当前水量和上次漏水时间
        pipe.hget(f"leaky_bucket:{key}", "water")
        pipe.hget(f"leaky_bucket:{key}", "last_leak")

        results = await pipe.execute()

        water = float(results[0] or 0)
        last_leak = float(results[1] or current_time)

        # 计算漏出的水量
        time_diff = current_time - last_leak
        leak_rate = config.limit / config.window
        leaked = min(water, time_diff * leak_rate)
        new_water = water - leaked + weight

        bucket_capacity = config.burst_limit or config.limit

        if new_water <= bucket_capacity:
            # 更新漏桶
            await self.redis_client.hset(f"leaky_bucket:{key}", mapping={
                "water": new_water,
                "last_leak": current_time
            })
            await self.redis_client.expire(f"leaky_bucket:{key}", config.window)

            return True
        else:
            return False

    async def _acquire_local_permit(self, key: str, config: RateLimitConfig, weight: int) -> bool:
        """本地速率限制"""
        current_time = time.time()

        # 定期清理过期的计数器
        if current_time - self.last_cleanup > self.cleanup_interval:
            await self._cleanup_expired_counters()
            self.last_cleanup = current_time

        if config.algorithm == RateLimitAlgorithm.SLIDING_WINDOW:
            return await self._sliding_window_local(key, config, weight)
        elif config.algorithm == RateLimitAlgorithm.TOKEN_BUCKET:
            return await self._token_bucket_local(key, config, weight)
        else:
            return await self._fixed_window_local(key, config, weight)

    async def _sliding_window_local(self, key: str, config: RateLimitConfig, weight: int) -> bool:
        """本地滑动窗口算法"""
        current_time = time.time()
        window_start = current_time - config.window

        if key not in self.local_counters:
            self.local_counters[key] = deque()

        # 清理窗口外的请求
        window = self.local_counters[key]
        while window and window[0] <= window_start:
            window.popleft()

        if len(window) + weight <= config.limit:
            # 添加当前请求
            for _ in range(weight):
                window.append(current_time)
            return True
        else:
            return False

    async def _token_bucket_local(self, key: str, config: RateLimitConfig, weight: int) -> bool:
        """本地令牌桶算法"""
        current_time = time.time()

        if key not in self.local_counters:
            self.local_counters[key] = {
                'tokens': config.limit,
                'last_refill': current_time
            }

        bucket = self.local_counters[key]

        # 计算补充的令牌
        time_diff = current_time - bucket['last_refill']
        refill_rate = config.limit / config.window
        new_tokens = min(config.limit, bucket['tokens'] + time_diff * refill_rate)

        if new_tokens >= weight:
            bucket['tokens'] = new_tokens - weight
            bucket['last_refill'] = current_time
            return True
        else:
            return False

    async def _fixed_window_local(self, key: str, config: RateLimitConfig, weight: int) -> bool:
        """本地固定窗口算法"""
        current_time = time.time()
        window = int(current_time // config.window)

        window_key = f"{key}:{window}"

        if window_key not in self.local_counters:
            self.local_counters[window_key] = 0

        if self.local_counters[window_key] + weight <= config.limit:
            self.local_counters[window_key] += weight
            return True
        else:
            return False

    async def _cleanup_expired_counters(self):
        """清理过期的计数器"""
        current_time = time.time()
        expired_keys = []

        for key, data in self.local_counters.items():
            if isinstance(data, deque) and data:
                if data[-1] < current_time - 3600:  # 1小时前
                    expired_keys.append(key)
            elif isinstance(data, dict) and 'last_refill' in data:
                if data['last_refill'] < current_time - 3600:
                    expired_keys.append(key)
            else:
                window_key_parts = key.split(':')
                if len(window_key_parts) >= 2:
                    try:
                        window = int(window_key_parts[-1])
                        window_start = window * 60  # 假设60秒窗口
                        if window_start < current_time - 3600:
                            expired_keys.append(key)
                    except ValueError:
                        pass

        for key in expired_keys:
            del self.local_counters[key]

    async def get_remaining_requests(self, key: str) -> int:
        """获取剩余请求数"""
        if key not in self.configs:
            return float('inf')

        config = self.configs[key]

        if self.redis_client:
            return await self._get_redis_remaining(key, config)
        else:
            return await self._get_local_remaining(key, config)

    async def _get_redis_remaining(self, key: str, config: RateLimitConfig) -> int:
        """获取Redis剩余请求数"""
        try:
            if config.algorithm == RateLimitAlgorithm.SLIDING_WINDOW:
                current_time = time.time()
                window_start = current_time - config.window
                current_count = await self.redis_client.zcount(f"rate_limit:{key}", window_start, current_time)
                return max(0, config.limit - int(current_count))
            else:
                # 其他算法的实现
                return config.limit
        except Exception as e:
            self.logger.error(f"获取Redis剩余请求数失败: {e}")
            return config.limit

    async def _get_local_remaining(self, key: str, config: RateLimitConfig) -> int:
        """获取本地剩余请求数"""
        if key in self.local_counters:
            if isinstance(self.local_counters[key], deque):
                return max(0, config.limit - len(self.local_counters[key]))
            elif isinstance(self.local_counters[key], dict) and 'tokens' in self.local_counters[key]:
                return int(self.local_counters[key]['tokens'])

        return config.limit

class CircuitBreaker:
    """熔断器"""

    def __init__(self, name: str, config: CircuitBreakerConfig = None):
        self.name = name
        self.config = config or CircuitBreakerConfig()
        self.state = CircuitState.CLOSED
        self.failure_count = 0
        self.success_count = 0
        self.last_failure_time = 0
        self.last_state_change = time.time()
        self.logger = get_logger(f"circuit_breaker_{name}")

    async def call(self, func, *args, **kwargs):
        """调用受保护的函数"""
        if self.state == CircuitState.OPEN:
            if time.time() - self.last_failure_time > self.config.timeout:
                # 尝试进入半开状态
                self._set_state(CircuitState.HALF_OPEN)
                self.logger.info(f"熔断器 {self.name} 进入半开状态")
            else:
                raise CircuitBreakerError(f"熔断器 {self.name} 处于开启状态")

        try:
            # 添加超时保护
            result = await asyncio.wait_for(
                func(*args, **kwargs),
                timeout=self.config.call_timeout
            )

            # 成功调用
            self._on_success()
            return result

        except Exception as e:
            # 失败调用
            self._on_failure(e)
            raise

    def _on_success(self):
        """成功调用处理"""
        self.failure_count = 0
        self.success_count += 1

        if self.state == CircuitState.HALF_OPEN:
            if self.success_count >= self.config.recovery_threshold:
                self._set_state(CircuitState.CLOSED)
                self.logger.info(f"熔断器 {self.name} 恢复到关闭状态")

    def _on_failure(self, error: Exception):
        """失败调用处理"""
        self.failure_count += 1
        self.success_count = 0
        self.last_failure_time = time.time()

        if self.state == CircuitState.CLOSED:
            if self.failure_count >= self.config.failure_threshold:
                self._set_state(CircuitState.OPEN)
                self.logger.warning(f"熔断器 {self.name} 开启")
        elif self.state == CircuitState.HALF_OPEN:
            self._set_state(CircuitState.OPEN)
            self.logger.warning(f"熔断器 {self.name} 在半开状态下再次失败")

    def _set_state(self, new_state: CircuitState):
        """设置熔断器状态"""
        old_state = self.state
        self.state = new_state
        self.last_state_change = time.time()

        # 记录状态变化指标
        metrics.record_circuit_breaker_state_change(
            name=self.name,
            old_state=old_state.value,
            new_state=new_state.value
        )

    def get_state(self) -> Dict[str, Any]:
        """获取熔断器状态"""
        return {
            "name": self.name,
            "state": self.state.value,
            "failure_count": self.failure_count,
            "success_count": self.success_count,
            "last_failure_time": self.last_failure_time,
            "last_state_change": self.last_state_change
        }

class FailoverManager:
    """故障转移管理器"""

    def __init__(self):
        self.logger = get_logger("failover_manager")
        self.services = {}
        self.health_checks = {}
        self.failover_policies = {}
        self._running = False

    async def initialize(self):
        """初始化故障转移管理器"""
        # 加载配置
        failover_config = config.get('failover', {})

        for service_name, service_config in failover_config.items():
            await self._register_service(service_name, service_config)

        self.logger.info(f"故障转移管理器初始化完成，注册 {len(self.services)} 个服务")

    async def _register_service(self, service_name: str, config: Dict[str, Any]):
        """注册服务"""
        self.services[service_name] = {
            'instances': config.get('instances', []),
            'active_instance': 0,
            'health_check_interval': config.get('health_check_interval', 30),
            'failover_threshold': config.get('failover_threshold', 3),
            'recovery_threshold': config.get('recovery_threshold', 5),
            'failures': defaultdict(int),
            'successes': defaultdict(int)
        }

        # 注册健康检查
        self.health_checks[service_name] = asyncio.create_task(
            self._health_check_loop(service_name)
        )

    async def _health_check_loop(self, service_name: str):
        """健康检查循环"""
        while self._running:
            try:
                await self._perform_health_check(service_name)
                await asyncio.sleep(self.services[service_name]['health_check_interval'])
            except Exception as e:
                self.logger.error(f"服务 {service_name} 健康检查失败: {e}")
                await asyncio.sleep(5)

    async def _perform_health_check(self, service_name: str):
        """执行健康检查"""
        service = self.services[service_name]
        instances = service['instances']

        for i, instance in enumerate(instances):
            try:
                # 执行健康检查（这里应该调用实际的健康检查方法）
                is_healthy = await self._check_instance_health(instance)

                if is_healthy:
                    service['successes'][i] += 1
                    service['failures'][i] = 0
                else:
                    service['failures'][i] += 1
                    service['successes'][i] = 0

                # 检查是否需要故障转移
                if i == service['active_instance'] and not is_healthy:
                    if service['failures'][i] >= service['failover_threshold']:
                        await self._perform_failover(service_name)

                # 检查是否可以恢复
                elif i != service['active_instance'] and is_healthy:
                    if service['successes'][i] >= service['recovery_threshold']:
                        await self._perform_recovery(service_name, i)

            except Exception as e:
                self.logger.error(f"实例 {instance} 健康检查异常: {e}")
                service['failures'][i] += 1

    async def _check_instance_health(self, instance: str) -> bool:
        """检查实例健康状态"""
        # 这里应该实现实际的健康检查逻辑
        # 例如：ping、HTTP请求、数据库查询等
        try:
            # 模拟健康检查
            return True
        except Exception:
            return False

    async def _perform_failover(self, service_name: str):
        """执行故障转移"""
        service = self.services[service_name]
        current_active = service['active_instance']
        instances = service['instances']

        # 寻找下一个健康的实例
        for i in range(len(instances)):
            next_index = (current_active + i + 1) % len(instances)
            if service['failures'][next_index] < service['failover_threshold']:
                service['active_instance'] = next_index
                self.logger.warning(f"服务 {service_name} 故障转移: 实例 {current_active} -> 实例 {next_index}")

                # 记录指标
                metrics.record_failover(service_name, current_active, next_index)
                break

    async def _perform_recovery(self, service_name: str, instance_index: int):
        """执行恢复"""
        service = self.services[service_name]
        current_active = service['active_instance']

        # 检查是否应该恢复到原实例（如果原实例更优）
        if instance_index < current_active:
            service['active_instance'] = instance_index
            self.logger.info(f"服务 {service_name} 恢复到实例 {instance_index}")

            # 记录指标
            metrics.record_recovery(service_name, current_active, instance_index)

    async def start(self):
        """启动故障转移管理器"""
        self._running = True
        self.logger.info("故障转移管理器启动")

    async def stop(self):
        """停止故障转移管理器"""
        self._running = False

        # 停止所有健康检查任务
        for task in self.health_checks.values():
            task.cancel()

        self.logger.info("故障转移管理器已停止")

    def get_service_status(self, service_name: str) -> Dict[str, Any]:
        """获取服务状态"""
        if service_name not in self.services:
            return {}

        service = self.services[service_name]
        return {
            "service_name": service_name,
            "active_instance": service['active_instance'],
            "instances": service['instances'],
            "failures": dict(service['failures']),
            "successes": dict(service['successes'])
        }

# 全局实例
rate_limiter = AdvancedRateLimiter()
failover_manager = FailoverManager()
```

## 接受标准

### 必须满足的条件
- [ ] 实现多种速率限制算法（滑动窗口、令牌桶、漏桶等）
- [ ] 支持分布式和本地速率限制
- [ ] 实现完整的熔断器机制
- [ ] 支持智能故障检测和自动恢复
- [ ] 提供实时监控和统计功能
- [ ] 支持动态配置调整
- [ ] 实现优雅的服务降级
- [ ] 通过高并发和异常情况测试
- [ ] 完整的错误处理和日志记录

### 性能要求
- **速率限制精度**: 误差 < 1%
- **故障检测时间**: < 10秒
- **故障恢复时间**: < 30秒
- **熔断响应时间**: < 1ms
- **并发处理能力**: 支持10000+并发请求

### 技术规范
- 使用异步编程模型
- 基于Redis的分布式架构
- 支持配置热更新
- 完整的监控和告警机制
- 可扩展的插件架构

## 实现步骤

### 第一阶段：速率限制器 (2天)
1. 设计速率限制架构
2. 实现多种限制算法
3. 添加Redis分布式支持
4. 实现本地限制作为备选

### 第二阶段：熔断器 (1.5天)
1. 实现熔断器核心逻辑
2. 添加状态管理和转换
3. 实现自动恢复机制
4. 集成监控指标

### 第三阶段：故障转移 (1.5天)
1. 实现故障检测机制
2. 开发自动故障转移
3. 添加健康检查功能
4. 实现恢复策略

### 第四阶段：集成和测试 (1天)
1. 与现有系统集成
2. 进行性能测试
3. 故障场景测试
4. 优化和完善

## 交付物

### 文档
- 速率限制和故障转移设计文档
- API接口文档
- 配置说明文档
- 监控指标文档

### 代码
- 高级速率限制器实现
- 熔断器实现
- 故障转移管理器
- 监控和统计模块
- 单元测试和集成测试

### 配置
- 速率限制配置模板
- 熔断器配置
- 故障转移策略配置
- 监控配置

## 风险和依赖

### 技术风险
- 分布式速率限制的准确性
- 熔断器的误判和漏判
- 故障转移的复杂性和可靠性

### 依赖关系
- 依赖于Redis集群的稳定性
- 依赖于网络环境的可靠性
- 依赖于监控系统的完整性

### 缓解措施
- 实现多层级的降级机制
- 添加完善的监控和告警
- 实现配置验证和测试机制

## 验收标准
- 速率限制精确有效
- 熔断器正常工作
- 故障转移机制可靠
- 系统在高负载下稳定
- 监控指标完整准确
- 通过所有测试用例