#!/usr/bin/env python3
"""
æµ‹è¯•OnchainAnalystçš„AIå¢å¼ºåˆ†æåŠŸèƒ½
"""

import sys
import os
from pathlib import Path
import json
from typing import Dict, Any

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from src.crypto_trading_agents.agents.analysts.onchain_analyst import OnchainAnalyst
from src.crypto_trading_agents.config.ai_analysis_config import get_ai_analysis_config

def create_test_config() -> Dict[str, Any]:
    """åˆ›å»ºæµ‹è¯•é…ç½®"""
    config = {
        # åŸºç¡€é…ç½®
        "crypto_config": {
            "supported_chains": ["ethereum", "bitcoin", "solana", "polygon", "binance-smart-chain"]
        },
        
        # AIé…ç½® - ä½¿ç”¨æ¼”ç¤ºæ¨¡å¼é¿å…éœ€è¦çœŸå®API key
        "ai_analysis_config": {
            "enabled": True,
            "temperature": 0.1,
            "max_tokens": 3000,
        },
        
        "llm_config": {
            "provider": "demo",  # ä½¿ç”¨æ¼”ç¤ºæ¨¡å¼
            "model": "demo-model",
            "api_key": "demo-key",
        }
    }
    
    return config

def create_mock_onchain_data() -> Dict[str, Any]:
    """åˆ›å»ºæ¨¡æ‹Ÿé“¾ä¸Šæ•°æ®"""
    return {
        "symbol": "BTC/USDT",
        "base_currency": "BTC", 
        "chain": "bitcoin",
        "end_date": "2024-01-15",
        
        # æ´»è·ƒåœ°å€æ•°æ®
        "active_addresses": {
            "daily_active": 920000,
            "weekly_active": 3800000,
            "monthly_active": 9200000,
            "growth_rate_7d": 0.08,
            "growth_rate_30d": 0.15,
            "historical_avg": 820000,
            "percentile": 82,
        },
        
        # äº¤æ˜“æŒ‡æ ‡æ•°æ®
        "transaction_metrics": {
            "daily_transactions": 1380000,
            "average_fee": 18.5,
            "total_fees": 25530000,
            "large_transactions": 1580,
            "transaction_growth": 0.12,
            "fee_trend": "increasing",
        },
        
        # äº¤æ˜“æ‰€æµé‡æ•°æ®
        "exchange_flows": {
            "exchange_inflows": 18500,
            "exchange_outflows": 15200,
            "net_flow": -3300,  # å‡€æµå‡º
            "inflow_trend": "decreasing",
            "outflow_trend": "increasing", 
            "exchange_balance": 2800000,
            "balance_change_24h": -0.15,
        },
        
        # å·¨é²¸æ´»åŠ¨æ•°æ®
        "whale_activity": {
            "whale_transactions": 52,
            "whale_inflows": 9200,
            "whale_outflows": 7100,
            "net_whale_flow": -2100,
            "whale_concentration": 0.58,
            "large_holder_count": 9200,
            "accumulation_pattern": True,
        },
        
        # ç½‘ç»œå¥åº·æ•°æ® (BTC)
        "network_health": {
            "hash_rate": 520000000000000,  # 520 EH/s
            "difficulty": 78000000000000,
            "mining_revenue": 42000000,
            "network_nodes": 16500,
            "network_uptime": 0.9998,
        },
        
        # DeFiæŒ‡æ ‡æ•°æ®
        "defi_metrics": {
            "tvl": 28000000000,  # 280äº¿ç¾å…ƒ
            "defi_users": 5200000,
            "protocol_count": 420,
            "lending_volume": 950000000,
            "dex_volume": 1350000000,
            "yield_farming_tvl": 9200000000,
        },
        
        # æŒå¸åˆ†å¸ƒæ•°æ®
        "holder_distribution": {
            "top_10_holders": 0.12,
            "top_100_holders": 0.32,
            "retail_holders": 0.68,
            "holder_growth": 0.09,
            "average_balance": 0.92,
            "gini_coefficient": 0.68,
        }
    }

class MockLLMAdapter:
    """æ¨¡æ‹ŸLLMé€‚é…å™¨ç”¨äºæµ‹è¯•"""
    
    def invoke(self, messages):
        """æ¨¡æ‹ŸLLMè°ƒç”¨"""
        class MockResponse:
            def __init__(self, content):
                self.content = content
        
        # è¿”å›æ¨¡æ‹Ÿçš„JSONæ ¼å¼AIåˆ†æç»“æœ
        mock_analysis = {
            "network_health_analysis": {
                "current_status": "å¥åº·",
                "growth_sustainability": "å¯æŒç»­",
                "network_maturity": "æˆç†ŸæœŸ",
                "development_trend": "ä¸Šå‡"
            },
            "capital_flow_analysis": {
                "exchange_flow_signal": "ç§¯ç´¯",
                "whale_behavior_impact": "çœ‹æ¶¨",
                "institutional_activity": "å¢åŠ ",
                "retail_participation": "æ´»è·ƒ"
            },
            "defi_ecosystem_assessment": {
                "tvl_trend": "å¢é•¿",
                "innovation_level": "é«˜",
                "adoption_rate": "å¿«é€Ÿ",
                "risk_level": "ä¸­"
            },
            "onchain_sentiment": {
                "overall_sentiment": "çœ‹æ¶¨",
                "sentiment_strength": 0.75,
                "divergence_signals": ["äº¤æ˜“æ‰€å‡€æµå‡º", "å·¨é²¸ç§¯ç´¯"],
                "turning_point_probability": 0.25
            },
            "investment_recommendation": {
                "timeframe": "ä¸­æœŸ",
                "recommendation": "çœ‹æ¶¨",
                "key_monitoring_metrics": ["äº¤æ˜“æ‰€ä½™é¢å˜åŒ–", "å·¨é²¸æµé‡", "ç½‘ç»œæ´»è·ƒåº¦"],
                "entry_signals": ["æŒç»­å‡€æµå‡º", "ç½‘ç»œæ´»è·ƒåº¦å¢é•¿"],
                "exit_signals": ["å¤§é‡æµå…¥äº¤æ˜“æ‰€", "ç½‘ç»œæ´»è·ƒåº¦ä¸‹é™"]
            },
            "market_cycle_analysis": {
                "current_phase": "ç‰›å¸‚ä¸­æœŸ",
                "cycle_confidence": 0.8,
                "transition_indicators": ["é“¾ä¸Šæ´»è·ƒåº¦", "æœºæ„é‡‡ç”¨ç‡"],
                "historical_comparison": "ç›¸ä¼¼"
            },
            "risk_opportunities": {
                "primary_risks": ["ç›‘ç®¡ä¸ç¡®å®šæ€§", "æŠ€æœ¯é£é™©"],
                "key_opportunities": ["æœºæ„é‡‡ç”¨å¢åŠ ", "DeFiç”Ÿæ€å‘å±•"],
                "risk_mitigation": ["åˆ†æ•£æŠ•èµ„", "å®šæœŸç›‘æ§é“¾ä¸ŠæŒ‡æ ‡"]
            },
            "confidence_assessment": {
                "analysis_confidence": 0.82,
                "data_quality_score": 0.95,
                "prediction_reliability": "é«˜"
            },
            "executive_summary": "åŸºäºé“¾ä¸Šæ•°æ®åˆ†æï¼ŒBTCå½“å‰å¤„äºå¥åº·çš„ä¸Šå‡è¶‹åŠ¿ä¸­ã€‚äº¤æ˜“æ‰€å‡€æµå‡ºã€å·¨é²¸ç§¯ç´¯è¡Œä¸ºä»¥åŠç½‘ç»œæ´»è·ƒåº¦çš„æŒç»­å¢é•¿éƒ½è¡¨æ˜å¸‚åœºå¤„äºç§¯ç´¯é˜¶æ®µã€‚å»ºè®®ä¸­æœŸçœ‹æ¶¨ï¼Œä½†éœ€å¯†åˆ‡ç›‘æ§äº¤æ˜“æ‰€æµé‡å˜åŒ–å’Œç½‘ç»œæŒ‡æ ‡ã€‚"
        }
        
        return MockResponse(json.dumps(mock_analysis, ensure_ascii=False, indent=2))

def test_traditional_analysis():
    """æµ‹è¯•ä¼ ç»Ÿé“¾ä¸Šåˆ†æåŠŸèƒ½"""
    print("=== æµ‹è¯•ä¼ ç»Ÿé“¾ä¸Šåˆ†æåŠŸèƒ½ ===")
    
    # åˆ›å»ºé…ç½®ï¼Œç¦ç”¨AIåˆ†æ
    config = create_test_config()
    config["ai_analysis_config"]["enabled"] = False
    
    # åˆ›å»ºåˆ†æå¸ˆ
    analyst = OnchainAnalyst(config)
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    test_data = create_mock_onchain_data()
    
    # æ‰§è¡Œåˆ†æ
    result = analyst.analyze(test_data)
    
    print("ä¼ ç»Ÿåˆ†æç»“æœ:")
    print(f"- é“¾ä¸Šå¥åº·åº¦: {result.get('onchain_health', {}).get('status', 'unknown')}")
    print(f"- å¸‚åœºæƒ…ç»ª: {result.get('market_sentiment', {}).get('sentiment', 'unknown')}")
    print(f"- é£é™©ç­‰çº§: {result.get('risk_metrics', {}).get('risk_level', 'unknown')}")
    print(f"- ç½®ä¿¡åº¦: {result.get('confidence', 0):.2f}")
    print(f"- å…³é”®æ´å¯Ÿ: {len(result.get('key_insights', []))}æ¡")
    print()
    
    return result

def test_ai_enhanced_analysis():
    """æµ‹è¯•AIå¢å¼ºé“¾ä¸Šåˆ†æåŠŸèƒ½"""
    print("=== æµ‹è¯•AIå¢å¼ºé“¾ä¸Šåˆ†æåŠŸèƒ½ ===")
    
    # åˆ›å»ºå¯ç”¨AIçš„é…ç½®
    config = create_test_config()
    
    # åˆ›å»ºåˆ†æå¸ˆ
    analyst = OnchainAnalyst(config)
    
    # æ‰‹åŠ¨è®¾ç½®æ¨¡æ‹ŸLLMé€‚é…å™¨
    analyst.llm_adapter = MockLLMAdapter()
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    test_data = create_mock_onchain_data()
    
    # æ‰§è¡ŒAIå¢å¼ºåˆ†æ
    result = analyst.analyze(test_data)
    
    print("AIå¢å¼ºåˆ†æç»“æœ:")
    
    # ä¼ ç»Ÿåˆ†æéƒ¨åˆ†
    traditional = result.get("traditional_analysis", {})
    print(f"- ä¼ ç»Ÿåˆ†æç½®ä¿¡åº¦: {traditional.get('confidence', 0):.2f}")
    
    # AIåˆ†æéƒ¨åˆ†
    ai_analysis = result.get("ai_analysis", {})
    print(f"- AIåˆ†æç½®ä¿¡åº¦: {ai_analysis.get('confidence_assessment', {}).get('analysis_confidence', 0):.2f}")
    print(f"- AIæƒ…ç»ªåˆ¤æ–­: {ai_analysis.get('onchain_sentiment', {}).get('overall_sentiment', 'unknown')}")
    print(f"- AIæŠ•èµ„å»ºè®®: {ai_analysis.get('investment_recommendation', {}).get('recommendation', 'unknown')}")
    
    # å¢å¼ºæ´å¯Ÿ
    enhanced = result.get("enhanced_insights", {})
    sentiment_consensus = enhanced.get("sentiment_consensus", {})
    print(f"- æƒ…ç»ªä¸€è‡´æ€§: {sentiment_consensus.get('agreement', False)}")
    print(f"- ç»¼åˆç½®ä¿¡åº¦: {enhanced.get('confidence_assessment', {}).get('combined', 0):.2f}")
    
    # æœ€ç»ˆè¯„ä¼°
    final = result.get("final_assessment", {})
    print(f"- æœ€ç»ˆå»ºè®®: {final.get('overall_recommendation', 'unknown')}")
    print(f"- ç›‘æ§æŒ‡æ ‡: {len(final.get('monitoring_metrics', []))}ä¸ª")
    print(f"- æ‰§è¡Œæ€»ç»“: {final.get('executive_summary', 'N/A')[:100]}...")
    print()
    
    return result

def test_data_collection():
    """æµ‹è¯•æ•°æ®æ”¶é›†åŠŸèƒ½"""
    print("=== æµ‹è¯•æ•°æ®æ”¶é›†åŠŸèƒ½ ===")
    
    config = create_test_config()
    analyst = OnchainAnalyst(config)
    
    # æµ‹è¯•æ•°æ®æ”¶é›†
    collected_data = analyst.collect_data("BTC/USDT", "2024-01-15")
    
    print("æ•°æ®æ”¶é›†ç»“æœ:")
    print(f"- äº¤æ˜“å¯¹: {collected_data.get('symbol', 'unknown')}")
    print(f"- åŸºç¡€è´§å¸: {collected_data.get('base_currency', 'unknown')}")
    print(f"- åŒºå—é“¾: {collected_data.get('chain', 'unknown')}")
    print(f"- æ•°æ®å­—æ®µæ•°: {len(collected_data.keys())}")
    print()
    
    return collected_data

def display_analysis_comparison(traditional_result, ai_enhanced_result):
    """æ˜¾ç¤ºåˆ†æç»“æœå¯¹æ¯”"""
    print("=== ä¼ ç»Ÿåˆ†æ vs AIå¢å¼ºåˆ†æå¯¹æ¯” ===")
    
    # ç½®ä¿¡åº¦å¯¹æ¯”
    traditional_conf = traditional_result.get("confidence", 0)
    ai_enhanced_conf = ai_enhanced_result.get("enhanced_insights", {}).get("confidence_assessment", {}).get("combined", 0)
    
    print(f"ç½®ä¿¡åº¦å¯¹æ¯”:")
    print(f"- ä¼ ç»Ÿåˆ†æ: {traditional_conf:.2f}")
    print(f"- AIå¢å¼º: {ai_enhanced_conf:.2f}")
    print(f"- æå‡: {(ai_enhanced_conf - traditional_conf)*100:+.1f}%")
    print()
    
    # æƒ…ç»ªåˆ†æå¯¹æ¯”
    traditional_sentiment = traditional_result.get("market_sentiment", {}).get("sentiment", "unknown")
    ai_sentiment = ai_enhanced_result.get("ai_analysis", {}).get("onchain_sentiment", {}).get("overall_sentiment", "unknown")
    
    print(f"æƒ…ç»ªåˆ†æå¯¹æ¯”:")
    print(f"- ä¼ ç»Ÿåˆ†æ: {traditional_sentiment}")
    print(f"- AIåˆ†æ: {ai_sentiment}")
    print(f"- ä¸€è‡´æ€§: {ai_enhanced_result.get('enhanced_insights', {}).get('sentiment_consensus', {}).get('agreement', False)}")
    print()
    
    # æ´å¯Ÿä¸°å¯Œåº¦å¯¹æ¯”
    traditional_insights = len(traditional_result.get("key_insights", []))
    ai_monitoring_metrics = len(ai_enhanced_result.get("final_assessment", {}).get("monitoring_metrics", []))
    
    print(f"æ´å¯Ÿä¸°å¯Œåº¦:")
    print(f"- ä¼ ç»Ÿå…³é”®æ´å¯Ÿ: {traditional_insights}æ¡")
    print(f"- AIç›‘æ§æŒ‡æ ‡: {ai_monitoring_metrics}ä¸ª")
    print()

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ”— OnchainAnalyst AIå¢å¼ºåˆ†ææµ‹è¯•")
    print("=" * 50)
    
    try:
        # 1. æµ‹è¯•æ•°æ®æ”¶é›†
        collected_data = test_data_collection()
        
        # 2. æµ‹è¯•ä¼ ç»Ÿåˆ†æ
        traditional_result = test_traditional_analysis()
        
        # 3. æµ‹è¯•AIå¢å¼ºåˆ†æ
        ai_enhanced_result = test_ai_enhanced_analysis()
        
        # 4. å¯¹æ¯”åˆ†æç»“æœ
        display_analysis_comparison(traditional_result, ai_enhanced_result)
        
        # 5. ä¿å­˜æµ‹è¯•ç»“æœ
        test_results = {
            "timestamp": "2024-01-15T10:30:00",
            "collected_data": collected_data,
            "traditional_analysis": traditional_result,
            "ai_enhanced_analysis": ai_enhanced_result
        }
        
        with open("onchain_ai_test_results.json", "w", encoding="utf-8") as f:
            json.dump(test_results, f, ensure_ascii=False, indent=2)
        
        print("âœ… æ‰€æœ‰æµ‹è¯•å®Œæˆï¼ç»“æœå·²ä¿å­˜åˆ° onchain_ai_test_results.json")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()